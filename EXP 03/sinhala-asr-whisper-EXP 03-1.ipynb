{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2417210,"sourceType":"datasetVersion","datasetId":1462498},{"sourceId":12550390,"sourceType":"datasetVersion","datasetId":7924145}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================\n# SINHALA ASR TRAINING WITH WHISPER - KAGGLE VERSION\n# ================================\n\n# Install required packages\n%pip install transformers datasets evaluate jiwer\n%pip install librosa scikit-learn pandas\n%pip install soundfile\n%pip install tensorboard\n%pip install accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T03:53:46.103785Z","iopub.execute_input":"2025-07-24T03:53:46.104157Z","iopub.status.idle":"2025-07-24T03:55:26.742885Z","shell.execute_reply.started":"2025-07-24T03:53:46.104132Z","shell.execute_reply":"2025-07-24T03:55:26.742035Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nCollecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nCollecting jiwer\n  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, fsspec, jiwer, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0 jiwer-4.0.0 rapidfuzz-3.13.0\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.3->librosa) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.3->librosa) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->soundfile) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->soundfile) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ================================\n# IMPORTS\n# ================================\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport librosa\nimport os\nimport glob\nfrom datasets import Dataset, Audio\nfrom transformers import (\n    WhisperFeatureExtractor, \n    WhisperTokenizer, \n    WhisperProcessor,\n    WhisperForConditionalGeneration,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    EarlyStoppingCallback\n)\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\nimport evaluate\nfrom jiwer import wer, cer, mer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T03:55:26.744416Z","iopub.execute_input":"2025-07-24T03:55:26.744661Z","iopub.status.idle":"2025-07-24T03:56:03.252549Z","shell.execute_reply.started":"2025-07-24T03:55:26.744637Z","shell.execute_reply":"2025-07-24T03:56:03.251975Z"}},"outputs":[{"name":"stderr","text":"2025-07-24 03:55:42.756490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753329343.099337      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753329343.236106      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ================================\n# 1. DATA PREPARATION WITH KAGGLE PATHS\n# ================================\n\n# Define Kaggle paths\nAUDIO_small_PATH = \"/kaggle/input/large-sinhala-asr-training-dataset\"\nCSV_small_PATH = \"/kaggle/input/dataset\"\n\nprint(\"ğŸš€ Loading Sinhala ASR data for Kaggle training...\")\nprint(f\"ğŸ“ Audio small path: {AUDIO_small_PATH}\")\nprint(f\"ğŸ“ CSV small path: {CSV_small_PATH}\")\n\n# Verify paths exist\nif not os.path.exists(AUDIO_small_PATH):\n    print(f\"âŒ Audio path not found: {AUDIO_small_PATH}\")\n    raise FileNotFoundError(\"Audio dataset not found\")\n    \nif not os.path.exists(CSV_small_PATH):\n    print(f\"âŒ CSV path not found: {CSV_small_PATH}\")\n    raise FileNotFoundError(\"CSV files not found\")\n\nprint(\"âœ… All paths verified successfully!\")\n\n# Load CSV files\ntrain_csv = os.path.join(CSV_small_PATH, \"10-train.csv\")\ntest_csv = os.path.join(CSV_small_PATH, \"10-test.csv\")\n\ntrain_df = pd.read_csv(train_csv)\nval_df = pd.read_csv(test_csv)\n\nprint(f\"\\nğŸ“Š Dataset Information:\")\nprint(f\"   ğŸ‹ï¸ Training samples: {len(train_df):,}\")\nprint(f\"   ğŸ§ª Validation samples: {len(val_df):,}\")\nprint(f\"   ğŸ“ˆ Total samples: {len(train_df) + len(val_df):,}\")\n\n# Check data structure\nprint(f\"\\nğŸ” Data Structure:\")\nprint(f\"   ğŸ“‹ Train columns: {list(train_df.columns)}\")\nprint(f\"   ğŸ“‹ Val columns: {list(val_df.columns)}\")\n\n# Show sample data\nprint(f\"\\nğŸ“ Sample Training Data:\")\nprint(train_df.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T03:56:03.253284Z","iopub.execute_input":"2025-07-24T03:56:03.253843Z","iopub.status.idle":"2025-07-24T03:56:03.348908Z","shell.execute_reply.started":"2025-07-24T03:56:03.253803Z","shell.execute_reply":"2025-07-24T03:56:03.348191Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Loading Sinhala ASR data for Kaggle training...\nğŸ“ Audio small path: /kaggle/input/large-sinhala-asr-training-dataset\nğŸ“ CSV small path: /kaggle/input/dataset\nâœ… All paths verified successfully!\n\nğŸ“Š Dataset Information:\n   ğŸ‹ï¸ Training samples: 8,000\n   ğŸ§ª Validation samples: 2,000\n   ğŸ“ˆ Total samples: 10,000\n\nğŸ” Data Structure:\n   ğŸ“‹ Train columns: ['file', 'sentence_cleaned']\n   ğŸ“‹ Val columns: ['file', 'sentence_cleaned']\n\nğŸ“ Sample Training Data:\n                                  file              sentence_cleaned\n0  asr_sinhala/data/aa/aaaee62687.flac  à¶…à¶šà·Šà¶šà¶ºà·’ à¶¸à·à¶ºà·’ à¶¯à·™à¶±à·Šà¶±à¶­à·Š à·…à¶Ÿ à¶±à·à¶­à·”à·€\n1  asr_sinhala/data/07/07031079ca.flac      à·à·Šâ€à¶»à·“ à¶½à¶‚à¶šà·à·€ à¶¶à·à·„à·à¶» à¶šà·œà¶§ à¶‡à¶­\n2  asr_sinhala/data/31/3128fc4733.flac  à¶”à¶±à·Šà¶± à¶”à¶º à·€à·’à¶¯à·’à·„à¶§ à¶ºà·™à¶¯à·™à¶± à¶±à·à¶šà¶­à·™à¶±à·Š\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ================================\n# 2. PATH CONVERSION AND VALIDATION\n# ================================\n\ndef convert_audio_path(relative_path, small_path=AUDIO_small_PATH):\n    \"\"\"Convert relative audio path to absolute Kaggle path\"\"\"\n    if pd.isna(relative_path) or relative_path == \"\":\n        return None\n    \n    # Handle already absolute paths\n    if os.path.isabs(relative_path):\n        return relative_path\n    \n    # Join with small path\n    absolute_path = os.path.join(small_path, relative_path)\n    return os.path.normpath(absolute_path)\n\ndef verify_audio_file(audio_path):\n    \"\"\"Verify if audio file exists and is readable\"\"\"\n    try:\n        if not os.path.exists(audio_path):\n            return False\n        audio, sr = librosa.load(audio_path, sr=16000)\n        return len(audio) > 0\n    except Exception as e:\n        return False\n\n# Ensure consistent column naming\naudio_col = train_df.columns[0]\ntext_col = train_df.columns[1]\n\nprint(f\"ğŸ”„ Using columns: '{audio_col}' as audio, '{text_col}' as sentence\")\n\n# Rename columns for consistency\ntrain_df = train_df[[audio_col, text_col]].copy()\nval_df = val_df[[audio_col, text_col]].copy()\ntrain_df.columns = [\"audio\", \"sentence\"]\nval_df.columns = [\"audio\", \"sentence\"]\n\n# Convert relative paths to absolute paths\nprint(f\"\\nğŸ”— Converting audio paths...\")\ntrain_df['audio'] = train_df['audio'].apply(convert_audio_path)\nval_df['audio'] = val_df['audio'].apply(convert_audio_path)\n\n# Remove rows with missing data\ninitial_train_size = len(train_df)\ninitial_val_size = len(val_df)\n\ntrain_df = train_df.dropna()\nval_df = val_df.dropna()\ntrain_df = train_df[train_df[\"sentence\"].str.strip() != \"\"]\nval_df = val_df[val_df[\"sentence\"].str.strip() != \"\"]\n\nprint(f\"\\nğŸ” Validating audio files (this may take a moment)...\")\n\n# Validate audio files (sample check for speed)\nsample_size = min(1000, len(train_df))\ntrain_sample = train_df.head(sample_size)\nvalid_count = sum(verify_audio_file(path) for path in train_sample['audio'])\n\nprint(f\"ğŸ“Š Audio validation results:\")\nprint(f\"   âœ… Valid files in sample: {valid_count}/{sample_size}\")\nprint(f\"   ğŸ“ˆ Estimated validity rate: {valid_count/sample_size*100:.1f}%\")\n\nif valid_count < sample_size * 0.1:  # Less than 10% valid\n    print(\"âš ï¸ Warning: Low audio file validity rate detected\")\n    print(\"ğŸ’¡ Check if audio paths are correctly mapped\")\n\nprint(f\"\\nğŸ§¹ Data Cleaning Results:\")\nprint(f\"   ğŸ‹ï¸ Training: {initial_train_size} â†’ {len(train_df)} samples\")\nprint(f\"   ğŸ§ª Validation: {initial_val_size} â†’ {len(val_df)} samples\")\n\n# Display final sample data\nprint(f\"\\nğŸ“ Final Sample Data:\")\nprint(train_df.head(3))","metadata":{"execution":{"iopub.status.busy":"2025-07-24T03:56:03.350366Z","iopub.execute_input":"2025-07-24T03:56:03.350727Z","iopub.status.idle":"2025-07-24T03:56:24.939538Z","shell.execute_reply.started":"2025-07-24T03:56:03.350708Z","shell.execute_reply":"2025-07-24T03:56:24.938804Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ”„ Using columns: 'file' as audio, 'sentence_cleaned' as sentence\n\nğŸ”— Converting audio paths...\n\nğŸ” Validating audio files (this may take a moment)...\nğŸ“Š Audio validation results:\n   âœ… Valid files in sample: 1000/1000\n   ğŸ“ˆ Estimated validity rate: 100.0%\n\nğŸ§¹ Data Cleaning Results:\n   ğŸ‹ï¸ Training: 8000 â†’ 8000 samples\n   ğŸ§ª Validation: 2000 â†’ 2000 samples\n\nğŸ“ Final Sample Data:\n                                               audio  \\\n0  /kaggle/input/large-sinhala-asr-training-datas...   \n1  /kaggle/input/large-sinhala-asr-training-datas...   \n2  /kaggle/input/large-sinhala-asr-training-datas...   \n\n                       sentence  \n0  à¶…à¶šà·Šà¶šà¶ºà·’ à¶¸à·à¶ºà·’ à¶¯à·™à¶±à·Šà¶±à¶­à·Š à·…à¶Ÿ à¶±à·à¶­à·”à·€  \n1      à·à·Šâ€à¶»à·“ à¶½à¶‚à¶šà·à·€ à¶¶à·à·„à·à¶» à¶šà·œà¶§ à¶‡à¶­  \n2  à¶”à¶±à·Šà¶± à¶”à¶º à·€à·’à¶¯à·’à·„à¶§ à¶ºà·™à¶¯à·™à¶± à¶±à·à¶šà¶­à·™à¶±à·Š  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ================================\n# 3. WHISPER PROCESSOR SETUP\n# ================================\n\nprint(\"ğŸ¤– Setting up Whisper processor for Sinhala...\")\n\n# Initialize Whisper components for Sinhala\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"si\", task=\"transcribe\")\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"si\", task=\"transcribe\")\n\nprint(\"âœ… Whisper processor setup completed!\")\nprint(f\"   ğŸŒ Language: Sinhala (si)\")\nprint(f\"   ğŸ¯ Task: Transcribe\")\nprint(f\"   ğŸ“ Model: whisper-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T03:56:24.940300Z","iopub.execute_input":"2025-07-24T03:56:24.941033Z","iopub.status.idle":"2025-07-24T03:56:27.398541Z","shell.execute_reply.started":"2025-07-24T03:56:24.941005Z","shell.execute_reply":"2025-07-24T03:56:27.397762Z"}},"outputs":[{"name":"stdout","text":"ğŸ¤– Setting up Whisper processor for Sinhala...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"713fc07105be4afc97380a01252c3c1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c937792b624846db99c5c3c0a56e2334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7a45896795f450cb58da5fcbdc2c20d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f23107cd3941d0be876f62880e9265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7172774d32b6484cb7af32c4bd353b76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62966357787a4f629658aa16e2901206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1708553a6db4dcbb8b2a2ccc887772f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ff4f31c1f5e4bae86e7dcb2c8609524"}},"metadata":{}},{"name":"stdout","text":"âœ… Whisper processor setup completed!\n   ğŸŒ Language: Sinhala (si)\n   ğŸ¯ Task: Transcribe\n   ğŸ“ Model: whisper-small\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ================================\n# 4. AUDIO PREPROCESSING FUNCTIONS\n# ================================\n\ndef normalize_audio(audio_array):\n    \"\"\"Normalize audio to prevent clipping\"\"\"\n    max_val = np.max(np.abs(audio_array))\n    if max_val > 0:\n        return audio_array / max_val\n    return audio_array\n\ndef add_noise_augmentation(audio_array, noise_factor=0.005):\n    \"\"\"Add Gaussian noise for robustness\"\"\"\n    noise = np.random.normal(0, noise_factor, audio_array.shape)\n    return audio_array + noise\n\n# Filter valid audio files for training\nprint(\"ğŸ” Filtering valid audio files for training...\")\n\nvalid_train = []\nvalid_val = []\n\n# Process training data\nprint(\"Processing training data...\")\nfor idx, row in train_df.iterrows():\n    if verify_audio_file(row['audio']):\n        valid_train.append(row)\n    else:\n        if idx < 10:  # Only print first 10 invalid files\n            print(f\"   âš ï¸ Invalid audio: {os.path.smallname(row['audio'])}\")\n\n# Process validation data\nprint(\"Processing validation data...\")\nfor idx, row in val_df.iterrows():\n    if verify_audio_file(row['audio']):\n        valid_val.append(row)\n    else:\n        if idx < 10:  # Only print first 10 invalid files\n            print(f\"   âš ï¸ Invalid audio: {os.path.smallname(row['audio'])}\")\n\n# Update dataframes\ntrain_df = pd.DataFrame(valid_train)\nval_df = pd.DataFrame(valid_val)\n\nprint(f\"\\nğŸ“Š Final Valid Dataset:\")\nprint(f\"   ğŸ‹ï¸ Training samples: {len(train_df):,}\")\nprint(f\"   ğŸ§ª Validation samples: {len(val_df):,}\")\nprint(f\"   ğŸ“ˆ Total valid samples: {len(train_df) + len(val_df):,}\")\n\nif len(train_df) == 0:\n    raise ValueError(\"No valid training samples found! Check audio paths.\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T03:56:27.399408Z","iopub.execute_input":"2025-07-24T03:56:27.399660Z","iopub.status.idle":"2025-07-24T03:57:53.179641Z","shell.execute_reply.started":"2025-07-24T03:56:27.399640Z","shell.execute_reply":"2025-07-24T03:57:53.178941Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ” Filtering valid audio files for training...\nProcessing training data...\nProcessing validation data...\n\nğŸ“Š Final Valid Dataset:\n   ğŸ‹ï¸ Training samples: 8,000\n   ğŸ§ª Validation samples: 2,000\n   ğŸ“ˆ Total valid samples: 10,000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ================================\n# 5. DATASET CREATION\n# ================================\n\nprint(\"ğŸ“¦ Creating HuggingFace datasets...\")\n\n# Create datasets\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\n# Cast audio columns with target sampling rate\ntrain_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\nval_dataset = val_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n\ndef prepare_dataset(examples):\n    \"\"\"Prepare dataset with robust preprocessing\"\"\"\n    # Load and process audio\n    audio = examples[\"audio\"]\n    audio_array = audio[\"array\"]\n    \n    # Apply normalization\n    audio_array = normalize_audio(audio_array)\n    \n    # Optional: Add noise augmentation (uncomment if needed)\n    # audio_array = add_noise_augmentation(audio_array, noise_factor=0.001)\n    \n    # Ensure audio length constraints\n    min_length = 1000  # ~0.06 seconds at 16kHz\n    max_length = 480000  # ~30 seconds at 16kHz\n    \n    if len(audio_array) < min_length:\n        # Pad short audio\n        audio_array = np.pad(audio_array, (0, min_length - len(audio_array)), 'constant')\n    elif len(audio_array) > max_length:\n        # Truncate long audio\n        audio_array = audio_array[:max_length]\n    \n    # Compute log-Mel input features\n    examples[\"input_features\"] = feature_extractor(\n        audio_array, sampling_rate=16000\n    ).input_features[0]\n    \n    # Clean up audio data\n    del examples[\"audio\"]\n    \n    # Process text\n    sentences = examples[\"sentence\"]\n    \n    # Clean and normalize text\n    if isinstance(sentences, str):\n        sentences = sentences.strip()\n    \n    # Encode target text to label ids\n    examples[\"labels\"] = tokenizer(sentences).input_ids\n    del examples[\"sentence\"]\n    \n    return examples\n\n# Apply preprocessing\nprint(\"ğŸ”„ Preprocessing training dataset...\")\ntrain_dataset = train_dataset.map(prepare_dataset, num_proc=1)\n\nprint(\"ğŸ”„ Preprocessing validation dataset...\")\nval_dataset = val_dataset.map(prepare_dataset, num_proc=1)\n\nprint(\"âœ… Dataset preprocessing completed!\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T03:57:53.180390Z","iopub.execute_input":"2025-07-24T03:57:53.180669Z","iopub.status.idle":"2025-07-24T04:00:31.547403Z","shell.execute_reply.started":"2025-07-24T03:57:53.180636Z","shell.execute_reply":"2025-07-24T04:00:31.546528Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ“¦ Creating HuggingFace datasets...\nğŸ”„ Preprocessing training dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da3da7b76da4a97bfb7174cbaaf3f5b"}},"metadata":{}},{"name":"stdout","text":"ğŸ”„ Preprocessing validation dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"873b549883204af78b065e442f951084"}},"metadata":{}},{"name":"stdout","text":"âœ… Dataset preprocessing completed!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ================================\n# 6. DATA COLLATOR\n# ================================\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    \n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # Handle input features\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        \n        # Handle labels\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n        \n        # Replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n        \n        # Remove BOS token if present\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n        \n        batch[\"labels\"] = labels\n        return batch\n\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\nprint(\"âœ… Data collator configured!\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T04:00:31.548194Z","iopub.execute_input":"2025-07-24T04:00:31.548452Z","iopub.status.idle":"2025-07-24T04:00:31.556123Z","shell.execute_reply.started":"2025-07-24T04:00:31.548427Z","shell.execute_reply":"2025-07-24T04:00:31.555372Z"},"trusted":true},"outputs":[{"name":"stdout","text":"âœ… Data collator configured!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ================================\n# 7. EVALUATION METRICS\n# ================================\n\ndef compute_metrics(pred):\n    \"\"\"Compute comprehensive ASR evaluation metrics\"\"\"\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # Replace -100 with pad_token_id\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    # Decode token IDs to strings\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    # Calculate metrics\n    wer_score = wer(label_str, pred_str) * 100\n    cer_score = cer(label_str, pred_str) * 100\n    \n    # Sentence Error Rate\n    ser_score = (\n        sum(ref.strip() != pred.strip() for ref, pred in zip(label_str, pred_str))\n        / len(label_str)\n    ) * 100\n\n    return {\n        \"wer\": wer_score,\n        \"cer\": cer_score,\n        \"ser\": ser_score,\n    }\n\nprint(\"ğŸ“Š Evaluation metrics configured!\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T04:00:31.556933Z","iopub.execute_input":"2025-07-24T04:00:31.557213Z","iopub.status.idle":"2025-07-24T04:00:31.579899Z","shell.execute_reply.started":"2025-07-24T04:00:31.557188Z","shell.execute_reply":"2025-07-24T04:00:31.579338Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ“Š Evaluation metrics configured!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ================================\n# 8. MODEL SETUP\n# ================================\n\nprint(\"ğŸ¤– Loading pre-trained Whisper model...\")\n\ntry:\n    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n    print(\"âœ… Model loaded successfully!\")\nexcept Exception as e:\n    print(f\"âŒ Error loading model: {e}\")\n    raise\n\n# Configure model for Sinhala\nmodel.config.forced_decoder_ids = None\nmodel.config.suppress_tokens = []\n\n# Check device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"ğŸ’» Using device: {device}\")\n\nprint(f\"ğŸ“‹ Model Information:\")\nprint(f\"   ğŸ—ï¸ Architecture: {model.config.model_type}\")\nprint(f\"   ğŸ“ Model size: whisper-small\")\nprint(f\"   ğŸŒ Target language: Sinhala\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T04:00:31.582205Z","iopub.execute_input":"2025-07-24T04:00:31.582384Z","iopub.status.idle":"2025-07-24T04:00:37.746736Z","shell.execute_reply.started":"2025-07-24T04:00:31.582371Z","shell.execute_reply":"2025-07-24T04:00:37.745930Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ¤– Loading pre-trained Whisper model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373bee58da444d95990cb42b33ff2e66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a910b6dad55a446abe5d6bc77b851b53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"360542d20e4b4665a10f23e3976eee26"}},"metadata":{}},{"name":"stdout","text":"âœ… Model loaded successfully!\nğŸ’» Using device: cuda\nğŸ“‹ Model Information:\n   ğŸ—ï¸ Architecture: whisper\n   ğŸ“ Model size: whisper-small\n   ğŸŒ Target language: Sinhala\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ================================\n# 9. TRAINING ARGUMENTS\n# ================================\n\n# Output directory\noutput_dir = \"./whisper-sinhala-asr-model\"\n\n# training_args = Seq2SeqTrainingArguments(\n#     output_dir=output_dir,\n    \n#     # Training schedule\n#     num_train_epochs=12,\n#     per_device_train_batch_size=16,\n#     per_device_eval_batch_size=8,\n#     gradient_accumulation_steps=2,\n    \n#     # Optimization\n#     learning_rate=1.7e-05,\n#     warmup_steps=500,\n#     lr_scheduler_type=\"linear\",\n#     weight_decay=0.01,\n    \n#     # Evaluation and saving\n#     eval_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     save_total_limit=3,\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"wer\",\n#     greater_is_better=False,\n    \n#     # Memory optimization\n#     gradient_checkpointing=True,\n#     fp16=torch.cuda.is_available(),  # Use FP16 if CUDA available\n#     dataloader_pin_memory=False,\n    \n#     # Generation settings\n#     predict_with_generate=True,\n#     generation_max_length=225,\n    \n#     # Logging\n#     logging_steps=25,\n#     logging_strategy=\"steps\",\n#     report_to=[\"tensorboard\"],\n    \n#     # Additional settings\n#     remove_unused_columns=False,\n#     label_names=[\"labels\"],\n# )\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=output_dir,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    \n    # Evaluation and saving\n    save_total_limit=3,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    \n    # Batch sizes - adjusted for noisy data\n    per_device_train_batch_size=8,  # Reduced for stability\n    per_device_eval_batch_size=8,\n    # gradient_accumulation_steps=1,   # Compensate for smaller batch size\n    \n    # Learning rate - slightly lower for noisy data\n    learning_rate=1.7e-05,\n    warmup_steps=100,\n    lr_scheduler_type=\"linear\",\n    \n    # Memory optimization\n    gradient_checkpointing=True,\n    fp16=True,\n    dataloader_pin_memory=False,\n    \n    # Training duration\n    num_train_epochs=4,  # Reduced epochs for noisy data\n    \n    # Generation settings\n    predict_with_generate=True,\n    generation_max_length=225,\n    \n    # Logging\n    logging_steps=50,\n    report_to=[\"tensorboard\"],\n    \n    # Additional stability settings\n    max_grad_norm=1.0,\n    weight_decay=0.01,\n)\n\nprint(\"âš™ï¸ Training arguments configured!\")\nprint(f\"   ğŸ“ Output directory: {output_dir}\")\nprint(f\"   ğŸ”„ Epochs: {training_args.num_train_epochs}\")\nprint(f\"   ğŸ“¦ Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"   ğŸ“ˆ Learning rate: {training_args.learning_rate}\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T04:00:37.747450Z","iopub.execute_input":"2025-07-24T04:00:37.747668Z","iopub.status.idle":"2025-07-24T04:00:37.796968Z","shell.execute_reply.started":"2025-07-24T04:00:37.747653Z","shell.execute_reply":"2025-07-24T04:00:37.795994Z"},"trusted":true},"outputs":[{"name":"stdout","text":"âš™ï¸ Training arguments configured!\n   ğŸ“ Output directory: ./whisper-sinhala-asr-model\n   ğŸ”„ Epochs: 4\n   ğŸ“¦ Batch size: 8\n   ğŸ“ˆ Learning rate: 1.7e-05\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ================================\n# 10. TRAINER SETUP\n# ================================\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\nprint(\"ğŸƒâ€â™‚ï¸ Trainer configured successfully!\")\nprint(f\"   ğŸ‹ï¸ Training samples: {len(train_dataset):,}\")\nprint(f\"   ğŸ§ª Validation samples: {len(val_dataset):,}\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T04:00:37.798040Z","iopub.execute_input":"2025-07-24T04:00:37.798352Z","iopub.status.idle":"2025-07-24T04:00:41.791905Z","shell.execute_reply.started":"2025-07-24T04:00:37.798326Z","shell.execute_reply":"2025-07-24T04:00:41.791091Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3887636332.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"},{"name":"stdout","text":"ğŸƒâ€â™‚ï¸ Trainer configured successfully!\n   ğŸ‹ï¸ Training samples: 8,000\n   ğŸ§ª Validation samples: 2,000\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ================================\n# 11. TRAINING EXECUTION\n# ================================\n\nprint(\"ğŸš€ Starting Sinhala ASR training...\")\nprint(\"=\" * 50)\nprint(f\"ğŸ“Š Dataset: {len(train_dataset):,} training, {len(val_dataset):,} validation\")\nprint(f\"ğŸ¤– Model: Whisper-small fine-tuned for Sinhala\")\nprint(f\"ğŸ’» Device: {device}\")\nprint(f\"â±ï¸ Estimated time: ~{len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs // 100} minutes\")\nprint(\"=\" * 50)\n\n# Start training\ntry:\n    trainer.train()\n    print(\"âœ… Training completed successfully!\")\nexcept Exception as e:\n    print(f\"âŒ Training failed: {e}\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T04:00:41.792996Z","iopub.execute_input":"2025-07-24T04:00:41.793484Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Starting Sinhala ASR training...\n==================================================\nğŸ“Š Dataset: 8,000 training, 2,000 validation\nğŸ¤– Model: Whisper-small fine-tuned for Sinhala\nğŸ’» Device: cuda\nâ±ï¸ Estimated time: ~40 minutes\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1504' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1504/2000 6:40:38 < 2:12:18, 0.06 it/s, Epoch 3.01/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n      <th>Cer</th>\n      <th>Ser</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.212500</td>\n      <td>0.211231</td>\n      <td>57.217701</td>\n      <td>15.330729</td>\n      <td>91.800000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.134600</td>\n      <td>0.179160</td>\n      <td>51.187159</td>\n      <td>13.501484</td>\n      <td>87.600000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.067500</td>\n      <td>0.184831</td>\n      <td>49.526251</td>\n      <td>12.823498</td>\n      <td>86.900000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 12. MODEL SAVING\n# ================================\n\nimport shutil\n\n# Clean up any existing model directory\nmodel_save_dir = \"./sinhala-whisper-asr-final\"\nif os.path.exists(model_save_dir):\n    try:\n        shutil.rmtree(model_save_dir)\n        print(f\"ğŸ—‘ï¸ Cleaned up existing directory: {model_save_dir}\")\n    except:\n        pass\n\n# Create fresh directory\nos.makedirs(model_save_dir, exist_ok=True)\n\ntry:\n    print(\"ğŸ’¾ Saving trained Sinhala ASR model...\")\n    \n    # Save model\n    model.save_pretrained(model_save_dir, safe_serialization=False)\n    print(\"âœ… Model saved successfully!\")\n    \n    # Save processor\n    processor.save_pretrained(model_save_dir)\n    print(\"âœ… Processor saved successfully!\")\n    \n    # Verify saved files\n    saved_files = os.listdir(model_save_dir)\n    print(f\"ğŸ“ Saved files: {saved_files}\")\n    \n    print(f\"\\nğŸ‰ Sinhala ASR model training completed!\")\n    print(f\"ğŸ“ Model saved to: {model_save_dir}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Error saving model: {e}\")\n    print(\"ğŸ’¡ Trying alternative save method...\")\n    \n    # Alternative save method\n    torch.save(model.state_dict(), os.path.join(model_save_dir, \"pytorch_model.bin\"))\n    processor.save_pretrained(model_save_dir)\n    print(\"âœ… Alternative save completed!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_save_dir = \"./sinhala-whisper-asr-final\"\nmodel.save_pretrained(model_save_dir)\nprocessor.save_pretrained(model_save_dir)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"sinhala-whisper-asr-final\", 'zip', model_save_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"sinhala-whisper-asr-final.zip\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 12. CREATE DOWNLOADABLE ARCHIVES FOR KAGGLE\n# ================================\n\nimport os\nimport shutil\nimport zipfile\nfrom IPython.display import FileLink\n\ndef create_downloadable_archive(source_dir, archive_name):\n    \"\"\"Create a downloadable zip archive\"\"\"\n    if os.path.exists(source_dir):\n        # Create zip file\n        shutil.make_archive(archive_name, 'zip', source_dir)\n        zip_path = f\"{archive_name}.zip\"\n        \n        if os.path.exists(zip_path):\n            file_size = os.path.getsize(zip_path) / (1024 * 1024)  # Size in MB\n            print(f\"âœ… Created {zip_path} ({file_size:.2f} MB)\")\n            return zip_path\n        else:\n            print(f\"âŒ Failed to create {zip_path}\")\n            return None\n    else:\n        print(f\"âŒ Source directory {source_dir} does not exist\")\n        return None\n\n# Create downloadable archives\nprint(\"\\nğŸ”„ Creating downloadable model archives...\")\n\n# 1. Final trained model\nfinal_model_zip = create_downloadable_archive(\n    \"./whisper-sinhala-asr-model-final\", \n    \"whisper-sinhala-asr-model-final\"\n)\n\n# 2. Last checkpoint from training\ncheckpoint_dir = \"./whisper-sinhala-asr-model\"\nif os.path.exists(checkpoint_dir):\n    # Find the last checkpoint\n    checkpoints = [d for d in os.listdir(checkpoint_dir) if d.startswith(\"checkpoint-\")]\n    if checkpoints:\n        # Sort by checkpoint number\n        checkpoints.sort(key=lambda x: int(x.split(\"-\")[1]))\n        last_checkpoint = checkpoints[-1]\n        last_checkpoint_path = os.path.join(checkpoint_dir, last_checkpoint)\n        \n        print(f\"ğŸ“‚ Found last checkpoint: {last_checkpoint}\")\n        \n        # Create archive for last checkpoint\n        last_checkpoint_zip = create_downloadable_archive(\n            last_checkpoint_path, \n            f\"whisper-sinhala-asr-model-{last_checkpoint}\"\n        )\n    else:\n        print(\"âŒ No checkpoints found in training directory\")\n        last_checkpoint_zip = None\nelse:\n    print(\"âŒ Training directory does not exist\")\n    last_checkpoint_zip = None\n\n# 3. Training logs and metrics\nif os.path.exists(\"./whisper-sinhala-asr-model/runs\"):\n    tensorboard_logs_zip = create_downloadable_archive(\n        \"./whisper-sinhala-asr-model/runs\", \n        \"whisper-sinhala-asr-model-tensorboard-logs\"\n    )\nelse:\n    tensorboard_logs_zip = None\n\n# Create a comprehensive package with all files\nprint(\"\\nğŸ“¦ Creating comprehensive model package...\")\ncomprehensive_package = \"whisper-sinhala-asr-model-complete\"\nos.makedirs(comprehensive_package, exist_ok=True)\n\n# Copy final model\nif os.path.exists(\"./whisper-sinhala-asr-model-final\"):\n    shutil.copytree(\"./whisper-sinhala-asr-model-final\", \n                    f\"{comprehensive_package}/final_model\", \n                    dirs_exist_ok=True)\n\n# Copy last checkpoint\nif os.path.exists(last_checkpoint_path):\n    shutil.copytree(last_checkpoint_path, \n                    f\"{comprehensive_package}/last_checkpoint\", \n                    dirs_exist_ok=True)\n\n\n# Create comprehensive zip\ncomprehensive_zip = create_downloadable_archive(\n    comprehensive_package, \n    \"whisper-sinhala-asr-model-complete\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
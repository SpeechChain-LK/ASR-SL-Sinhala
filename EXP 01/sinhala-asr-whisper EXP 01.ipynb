{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-21T18:11:40.597654Z",
     "iopub.status.busy": "2025-07-21T18:11:40.597371Z",
     "iopub.status.idle": "2025-07-21T18:13:18.977049Z",
     "shell.execute_reply": "2025-07-21T18:13:18.976159Z",
     "shell.execute_reply.started": "2025-07-21T18:11:40.597630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, fsspec, jiwer, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0 jiwer-4.0.0 rapidfuzz-3.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2.4.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.3->librosa) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.3->librosa) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.3->librosa) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->soundfile) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->soundfile) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->soundfile) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# SINHALA ASR TRAINING WITH WHISPER - KAGGLE VERSION\n",
    "# ================================\n",
    "\n",
    "# Install required packages\n",
    "%pip install transformers datasets evaluate jiwer\n",
    "%pip install librosa scikit-learn pandas\n",
    "%pip install soundfile\n",
    "%pip install tensorboard\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:13:18.978994Z",
     "iopub.status.busy": "2025-07-21T18:13:18.978721Z",
     "iopub.status.idle": "2025-07-21T18:13:55.736014Z",
     "shell.execute_reply": "2025-07-21T18:13:55.735413Z",
     "shell.execute_reply.started": "2025-07-21T18:13:18.978971Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 18:13:34.191596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753121614.547955      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753121614.648770      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# IMPORTS\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import (\n",
    "    WhisperFeatureExtractor, \n",
    "    WhisperTokenizer, \n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import evaluate\n",
    "from jiwer import wer, cer, mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:13:55.737322Z",
     "iopub.status.busy": "2025-07-21T18:13:55.736708Z",
     "iopub.status.idle": "2025-07-21T18:13:55.814941Z",
     "shell.execute_reply": "2025-07-21T18:13:55.814325Z",
     "shell.execute_reply.started": "2025-07-21T18:13:55.737284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Loading Sinhala ASR data for Kaggle training...\n",
      "ğŸ“ Audio base path: /kaggle/input/large-sinhala-asr-training-dataset\n",
      "ğŸ“ CSV base path: /kaggle/input/new-dataset-10\n",
      "âœ… All paths verified successfully!\n",
      "\n",
      "ğŸ“Š Dataset Information:\n",
      "   ğŸ‹ï¸ Training samples: 8,000\n",
      "   ğŸ§ª Validation samples: 2,000\n",
      "   ğŸ“ˆ Total samples: 10,000\n",
      "\n",
      "ğŸ” Data Structure:\n",
      "   ğŸ“‹ Train columns: ['file', 'sentence_cleaned']\n",
      "   ğŸ“‹ Val columns: ['file', 'sentence_cleaned']\n",
      "\n",
      "ğŸ“ Sample Training Data:\n",
      "                                  file              sentence_cleaned\n",
      "0  asr_sinhala/data/aa/aaaee62687.flac  à¶…à¶šà·Šà¶šà¶ºà·’ à¶¸à·à¶ºà·’ à¶¯à·™à¶±à·Šà¶±à¶­à·Š à·…à¶Ÿ à¶±à·à¶­à·”à·€\n",
      "1  asr_sinhala/data/07/07031079ca.flac      à·à·Šâ€à¶»à·“ à¶½à¶‚à¶šà·à·€ à¶¶à·à·„à·à¶» à¶šà·œà¶§ à¶‡à¶­\n",
      "2  asr_sinhala/data/31/3128fc4733.flac  à¶”à¶±à·Šà¶± à¶”à¶º à·€à·’à¶¯à·’à·„à¶§ à¶ºà·™à¶¯à·™à¶± à¶±à·à¶šà¶­à·™à¶±à·Š\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. DATA PREPARATION WITH KAGGLE PATHS\n",
    "# ================================\n",
    "\n",
    "# Define Kaggle paths\n",
    "AUDIO_BASE_PATH = \"/kaggle/input/large-sinhala-asr-training-dataset\"\n",
    "CSV_BASE_PATH = \"/kaggle/input/new-dataset-10\"\n",
    "\n",
    "print(\"ğŸš€ Loading Sinhala ASR data for Kaggle training...\")\n",
    "print(f\"ğŸ“ Audio base path: {AUDIO_BASE_PATH}\")\n",
    "print(f\"ğŸ“ CSV base path: {CSV_BASE_PATH}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if not os.path.exists(AUDIO_BASE_PATH):\n",
    "    print(f\"âŒ Audio path not found: {AUDIO_BASE_PATH}\")\n",
    "    raise FileNotFoundError(\"Audio dataset not found\")\n",
    "    \n",
    "if not os.path.exists(CSV_BASE_PATH):\n",
    "    print(f\"âŒ CSV path not found: {CSV_BASE_PATH}\")\n",
    "    raise FileNotFoundError(\"CSV files not found\")\n",
    "\n",
    "print(\"âœ… All paths verified successfully!\")\n",
    "\n",
    "# Load CSV files\n",
    "train_csv = os.path.join(CSV_BASE_PATH, \"10-train.csv\")\n",
    "test_csv = os.path.join(CSV_BASE_PATH, \"10-test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "val_df = pd.read_csv(test_csv)\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Information:\")\n",
    "print(f\"   ğŸ‹ï¸ Training samples: {len(train_df):,}\")\n",
    "print(f\"   ğŸ§ª Validation samples: {len(val_df):,}\")\n",
    "print(f\"   ğŸ“ˆ Total samples: {len(train_df) + len(val_df):,}\")\n",
    "\n",
    "# Check data structure\n",
    "print(f\"\\nğŸ” Data Structure:\")\n",
    "print(f\"   ğŸ“‹ Train columns: {list(train_df.columns)}\")\n",
    "print(f\"   ğŸ“‹ Val columns: {list(val_df.columns)}\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nğŸ“ Sample Training Data:\")\n",
    "print(train_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:13:55.817062Z",
     "iopub.status.busy": "2025-07-21T18:13:55.816828Z",
     "iopub.status.idle": "2025-07-21T18:14:26.957895Z",
     "shell.execute_reply": "2025-07-21T18:14:26.957099Z",
     "shell.execute_reply.started": "2025-07-21T18:13:55.817045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Using columns: 'file' as audio, 'sentence_cleaned' as sentence\n",
      "\n",
      "ğŸ”— Converting audio paths...\n",
      "\n",
      "ğŸ” Validating audio files (this may take a moment)...\n",
      "ğŸ“Š Audio validation results:\n",
      "   âœ… Valid files in sample: 1000/1000\n",
      "   ğŸ“ˆ Estimated validity rate: 100.0%\n",
      "\n",
      "ğŸ§¹ Data Cleaning Results:\n",
      "   ğŸ‹ï¸ Training: 8000 â†’ 8000 samples\n",
      "   ğŸ§ª Validation: 2000 â†’ 2000 samples\n",
      "\n",
      "ğŸ“ Final Sample Data:\n",
      "                                               audio  \\\n",
      "0  /kaggle/input/large-sinhala-asr-training-datas...   \n",
      "1  /kaggle/input/large-sinhala-asr-training-datas...   \n",
      "2  /kaggle/input/large-sinhala-asr-training-datas...   \n",
      "\n",
      "                       sentence  \n",
      "0  à¶…à¶šà·Šà¶šà¶ºà·’ à¶¸à·à¶ºà·’ à¶¯à·™à¶±à·Šà¶±à¶­à·Š à·…à¶Ÿ à¶±à·à¶­à·”à·€  \n",
      "1      à·à·Šâ€à¶»à·“ à¶½à¶‚à¶šà·à·€ à¶¶à·à·„à·à¶» à¶šà·œà¶§ à¶‡à¶­  \n",
      "2  à¶”à¶±à·Šà¶± à¶”à¶º à·€à·’à¶¯à·’à·„à¶§ à¶ºà·™à¶¯à·™à¶± à¶±à·à¶šà¶­à·™à¶±à·Š  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. PATH CONVERSION AND VALIDATION\n",
    "# ================================\n",
    "\n",
    "def convert_audio_path(relative_path, base_path=AUDIO_BASE_PATH):\n",
    "    \"\"\"Convert relative audio path to absolute Kaggle path\"\"\"\n",
    "    if pd.isna(relative_path) or relative_path == \"\":\n",
    "        return None\n",
    "    \n",
    "    # Handle already absolute paths\n",
    "    if os.path.isabs(relative_path):\n",
    "        return relative_path\n",
    "    \n",
    "    # Join with base path\n",
    "    absolute_path = os.path.join(base_path, relative_path)\n",
    "    return os.path.normpath(absolute_path)\n",
    "\n",
    "def verify_audio_file(audio_path):\n",
    "    \"\"\"Verify if audio file exists and is readable\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(audio_path):\n",
    "            return False\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        return len(audio) > 0\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Ensure consistent column naming\n",
    "audio_col = train_df.columns[0]\n",
    "text_col = train_df.columns[1]\n",
    "\n",
    "print(f\"ğŸ”„ Using columns: '{audio_col}' as audio, '{text_col}' as sentence\")\n",
    "\n",
    "# Rename columns for consistency\n",
    "train_df = train_df[[audio_col, text_col]].copy()\n",
    "val_df = val_df[[audio_col, text_col]].copy()\n",
    "train_df.columns = [\"audio\", \"sentence\"]\n",
    "val_df.columns = [\"audio\", \"sentence\"]\n",
    "\n",
    "# Convert relative paths to absolute paths\n",
    "print(f\"\\nğŸ”— Converting audio paths...\")\n",
    "train_df['audio'] = train_df['audio'].apply(convert_audio_path)\n",
    "val_df['audio'] = val_df['audio'].apply(convert_audio_path)\n",
    "\n",
    "# Remove rows with missing data\n",
    "initial_train_size = len(train_df)\n",
    "initial_val_size = len(val_df)\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "val_df = val_df.dropna()\n",
    "train_df = train_df[train_df[\"sentence\"].str.strip() != \"\"]\n",
    "val_df = val_df[val_df[\"sentence\"].str.strip() != \"\"]\n",
    "\n",
    "print(f\"\\nğŸ” Validating audio files (this may take a moment)...\")\n",
    "\n",
    "# Validate audio files (sample check for speed)\n",
    "sample_size = min(1000, len(train_df))\n",
    "train_sample = train_df.head(sample_size)\n",
    "valid_count = sum(verify_audio_file(path) for path in train_sample['audio'])\n",
    "\n",
    "print(f\"ğŸ“Š Audio validation results:\")\n",
    "print(f\"   âœ… Valid files in sample: {valid_count}/{sample_size}\")\n",
    "print(f\"   ğŸ“ˆ Estimated validity rate: {valid_count/sample_size*100:.1f}%\")\n",
    "\n",
    "if valid_count < sample_size * 0.1:  # Less than 10% valid\n",
    "    print(\"âš ï¸ Warning: Low audio file validity rate detected\")\n",
    "    print(\"ğŸ’¡ Check if audio paths are correctly mapped\")\n",
    "\n",
    "print(f\"\\nğŸ§¹ Data Cleaning Results:\")\n",
    "print(f\"   ğŸ‹ï¸ Training: {initial_train_size} â†’ {len(train_df)} samples\")\n",
    "print(f\"   ğŸ§ª Validation: {initial_val_size} â†’ {len(val_df)} samples\")\n",
    "\n",
    "# Display final sample data\n",
    "print(f\"\\nğŸ“ Final Sample Data:\")\n",
    "print(train_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:14:26.959515Z",
     "iopub.status.busy": "2025-07-21T18:14:26.958796Z",
     "iopub.status.idle": "2025-07-21T18:14:29.312963Z",
     "shell.execute_reply": "2025-07-21T18:14:29.312216Z",
     "shell.execute_reply.started": "2025-07-21T18:14:26.959495Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Setting up Whisper processor for Sinhala...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b82dc671dc44a596d035b1e397b6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53f3418d50f41b189f490b5f0404e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bf67d4abc644d58b83f46966d957eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cfa5d78d2f45fba0f93f79b87e4e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41615948e48d44559da0ae0612004cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ee91f177e846c48044db64964c6ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16ace7790954142ad94ad8e7cfe6061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205867fb2e45485cb75ec2d6e60fcfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Whisper processor setup completed!\n",
      "   ğŸŒ Language: Sinhala (si)\n",
      "   ğŸ¯ Task: Transcribe\n",
      "   ğŸ“ Model: whisper-base\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. WHISPER PROCESSOR SETUP\n",
    "# ================================\n",
    "\n",
    "print(\"ğŸ¤– Setting up Whisper processor for Sinhala...\")\n",
    "\n",
    "# Initialize Whisper components for Sinhala\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"si\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"si\", task=\"transcribe\")\n",
    "\n",
    "print(\"âœ… Whisper processor setup completed!\")\n",
    "print(f\"   ğŸŒ Language: Sinhala (si)\")\n",
    "print(f\"   ğŸ¯ Task: Transcribe\")\n",
    "print(f\"   ğŸ“ Model: whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:14:29.314061Z",
     "iopub.status.busy": "2025-07-21T18:14:29.313785Z",
     "iopub.status.idle": "2025-07-21T18:16:45.048423Z",
     "shell.execute_reply": "2025-07-21T18:16:45.047792Z",
     "shell.execute_reply.started": "2025-07-21T18:14:29.314034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filtering valid audio files for training...\n",
      "Processing training data...\n",
      "Processing validation data...\n",
      "\n",
      "ğŸ“Š Final Valid Dataset:\n",
      "   ğŸ‹ï¸ Training samples: 8,000\n",
      "   ğŸ§ª Validation samples: 2,000\n",
      "   ğŸ“ˆ Total valid samples: 10,000\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 4. AUDIO PREPROCESSING FUNCTIONS\n",
    "# ================================\n",
    "\n",
    "def normalize_audio(audio_array):\n",
    "    \"\"\"Normalize audio to prevent clipping\"\"\"\n",
    "    max_val = np.max(np.abs(audio_array))\n",
    "    if max_val > 0:\n",
    "        return audio_array / max_val\n",
    "    return audio_array\n",
    "\n",
    "def add_noise_augmentation(audio_array, noise_factor=0.005):\n",
    "    \"\"\"Add Gaussian noise for robustness\"\"\"\n",
    "    noise = np.random.normal(0, noise_factor, audio_array.shape)\n",
    "    return audio_array + noise\n",
    "\n",
    "# Filter valid audio files for training\n",
    "print(\"ğŸ” Filtering valid audio files for training...\")\n",
    "\n",
    "valid_train = []\n",
    "valid_val = []\n",
    "\n",
    "# Process training data\n",
    "print(\"Processing training data...\")\n",
    "for idx, row in train_df.iterrows():\n",
    "    if verify_audio_file(row['audio']):\n",
    "        valid_train.append(row)\n",
    "    else:\n",
    "        if idx < 10:  # Only print first 10 invalid files\n",
    "            print(f\"   âš ï¸ Invalid audio: {os.path.basename(row['audio'])}\")\n",
    "\n",
    "# Process validation data\n",
    "print(\"Processing validation data...\")\n",
    "for idx, row in val_df.iterrows():\n",
    "    if verify_audio_file(row['audio']):\n",
    "        valid_val.append(row)\n",
    "    else:\n",
    "        if idx < 10:  # Only print first 10 invalid files\n",
    "            print(f\"   âš ï¸ Invalid audio: {os.path.basename(row['audio'])}\")\n",
    "\n",
    "# Update dataframes\n",
    "train_df = pd.DataFrame(valid_train)\n",
    "val_df = pd.DataFrame(valid_val)\n",
    "\n",
    "print(f\"\\nğŸ“Š Final Valid Dataset:\")\n",
    "print(f\"   ğŸ‹ï¸ Training samples: {len(train_df):,}\")\n",
    "print(f\"   ğŸ§ª Validation samples: {len(val_df):,}\")\n",
    "print(f\"   ğŸ“ˆ Total valid samples: {len(train_df) + len(val_df):,}\")\n",
    "\n",
    "if len(train_df) == 0:\n",
    "    raise ValueError(\"No valid training samples found! Check audio paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:16:45.049352Z",
     "iopub.status.busy": "2025-07-21T18:16:45.049138Z",
     "iopub.status.idle": "2025-07-21T18:19:35.720267Z",
     "shell.execute_reply": "2025-07-21T18:19:35.719396Z",
     "shell.execute_reply.started": "2025-07-21T18:16:45.049327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Creating HuggingFace datasets...\n",
      "ğŸ”„ Preprocessing training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31015b5aee2344c9a5c703f4a67cb5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Preprocessing validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a970b97fb029474cb2e4ee89b70b6572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. DATASET CREATION\n",
    "# ================================\n",
    "\n",
    "print(\"ğŸ“¦ Creating HuggingFace datasets...\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Cast audio columns with target sampling rate\n",
    "train_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "val_dataset = val_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "def prepare_dataset(examples):\n",
    "    \"\"\"Prepare dataset with robust preprocessing\"\"\"\n",
    "    # Load and process audio\n",
    "    audio = examples[\"audio\"]\n",
    "    audio_array = audio[\"array\"]\n",
    "    \n",
    "    # Apply normalization\n",
    "    audio_array = normalize_audio(audio_array)\n",
    "    \n",
    "    # Optional: Add noise augmentation (uncomment if needed)\n",
    "    # audio_array = add_noise_augmentation(audio_array, noise_factor=0.001)\n",
    "    \n",
    "    # Ensure audio length constraints\n",
    "    min_length = 1000  # ~0.06 seconds at 16kHz\n",
    "    max_length = 480000  # ~30 seconds at 16kHz\n",
    "    \n",
    "    if len(audio_array) < min_length:\n",
    "        # Pad short audio\n",
    "        audio_array = np.pad(audio_array, (0, min_length - len(audio_array)), 'constant')\n",
    "    elif len(audio_array) > max_length:\n",
    "        # Truncate long audio\n",
    "        audio_array = audio_array[:max_length]\n",
    "    \n",
    "    # Compute log-Mel input features\n",
    "    examples[\"input_features\"] = feature_extractor(\n",
    "        audio_array, sampling_rate=16000\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # Clean up audio data\n",
    "    del examples[\"audio\"]\n",
    "    \n",
    "    # Process text\n",
    "    sentences = examples[\"sentence\"]\n",
    "    \n",
    "    # Clean and normalize text\n",
    "    if isinstance(sentences, str):\n",
    "        sentences = sentences.strip()\n",
    "    \n",
    "    # Encode target text to label ids\n",
    "    examples[\"labels\"] = tokenizer(sentences).input_ids\n",
    "    del examples[\"sentence\"]\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"ğŸ”„ Preprocessing training dataset...\")\n",
    "train_dataset = train_dataset.map(prepare_dataset, num_proc=1)\n",
    "\n",
    "print(\"ğŸ”„ Preprocessing validation dataset...\")\n",
    "val_dataset = val_dataset.map(prepare_dataset, num_proc=1)\n",
    "\n",
    "print(\"âœ… Dataset preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:19:35.721304Z",
     "iopub.status.busy": "2025-07-21T18:19:35.721021Z",
     "iopub.status.idle": "2025-07-21T18:19:35.728557Z",
     "shell.execute_reply": "2025-07-21T18:19:35.728011Z",
     "shell.execute_reply.started": "2025-07-21T18:19:35.721276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data collator configured!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6. DATA COLLATOR\n",
    "# ================================\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    \n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Handle input features\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        \n",
    "        # Handle labels\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        \n",
    "        # Replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        \n",
    "        # Remove BOS token if present\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "        \n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "print(\"âœ… Data collator configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:19:35.729427Z",
     "iopub.status.busy": "2025-07-21T18:19:35.729249Z",
     "iopub.status.idle": "2025-07-21T18:19:35.755406Z",
     "shell.execute_reply": "2025-07-21T18:19:35.754781Z",
     "shell.execute_reply.started": "2025-07-21T18:19:35.729413Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Evaluation metrics configured!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 7. EVALUATION METRICS\n",
    "# ================================\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute comprehensive ASR evaluation metrics\"\"\"\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # Replace -100 with pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # Decode token IDs to strings\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Calculate metrics\n",
    "    wer_score = wer(label_str, pred_str) * 100\n",
    "    cer_score = cer(label_str, pred_str) * 100\n",
    "    \n",
    "    # Sentence Error Rate\n",
    "    ser_score = (\n",
    "        sum(ref.strip() != pred.strip() for ref, pred in zip(label_str, pred_str))\n",
    "        / len(label_str)\n",
    "    ) * 100\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer_score,\n",
    "        \"cer\": cer_score,\n",
    "        \"ser\": ser_score,\n",
    "    }\n",
    "\n",
    "print(\"ğŸ“Š Evaluation metrics configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:19:35.757634Z",
     "iopub.status.busy": "2025-07-21T18:19:35.757431Z",
     "iopub.status.idle": "2025-07-21T18:19:38.442897Z",
     "shell.execute_reply": "2025-07-21T18:19:38.442280Z",
     "shell.execute_reply.started": "2025-07-21T18:19:35.757620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Loading pre-trained Whisper model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62e61122f814c2b8fcdb33f16c288ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b27c23dd0241dba055960d364e1a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5798338e397e4159b50c3b54b20b6b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully!\n",
      "ğŸ’» Using device: cuda\n",
      "ğŸ“‹ Model Information:\n",
      "   ğŸ—ï¸ Architecture: whisper\n",
      "   ğŸ“ Model size: whisper-base\n",
      "   ğŸŒ Target language: Sinhala\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 8. MODEL SETUP\n",
    "# ================================\n",
    "\n",
    "print(\"ğŸ¤– Loading pre-trained Whisper model...\")\n",
    "\n",
    "try:\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Configure model for Sinhala\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ’» Using device: {device}\")\n",
    "\n",
    "print(f\"ğŸ“‹ Model Information:\")\n",
    "print(f\"   ğŸ—ï¸ Architecture: {model.config.model_type}\")\n",
    "print(f\"   ğŸ“ Model size: whisper-base\")\n",
    "print(f\"   ğŸŒ Target language: Sinhala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:19:38.444194Z",
     "iopub.status.busy": "2025-07-21T18:19:38.443800Z",
     "iopub.status.idle": "2025-07-21T18:19:38.491503Z",
     "shell.execute_reply": "2025-07-21T18:19:38.490777Z",
     "shell.execute_reply.started": "2025-07-21T18:19:38.444166Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Training arguments configured!\n",
      "   ğŸ“ Output directory: ./whisper-sinhala-asr-model\n",
      "   ğŸ”„ Epochs: 12\n",
      "   ğŸ“¦ Batch size: 16\n",
      "   ğŸ“ˆ Learning rate: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 9. TRAINING ARGUMENTS\n",
    "# ================================\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"./whisper-sinhala-asr-model\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    \n",
    "    # Training schedule\n",
    "    num_train_epochs=12,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Evaluation and saving\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Memory optimization\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=torch.cuda.is_available(),  # Use FP16 if CUDA available\n",
    "    dataloader_pin_memory=False,\n",
    "    \n",
    "    # Generation settings\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=25,\n",
    "    logging_strategy=\"steps\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    \n",
    "    # Additional settings\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ Training arguments configured!\")\n",
    "print(f\"   ğŸ“ Output directory: {output_dir}\")\n",
    "print(f\"   ğŸ”„ Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   ğŸ“¦ Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   ğŸ“ˆ Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:19:38.492426Z",
     "iopub.status.busy": "2025-07-21T18:19:38.492232Z",
     "iopub.status.idle": "2025-07-21T18:19:39.256480Z",
     "shell.execute_reply": "2025-07-21T18:19:39.255704Z",
     "shell.execute_reply.started": "2025-07-21T18:19:38.492409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/3887636332.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒâ€â™‚ï¸ Trainer configured successfully!\n",
      "   ğŸ‹ï¸ Training samples: 8,000\n",
      "   ğŸ§ª Validation samples: 2,000\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 10. TRAINER SETUP\n",
    "# ================================\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"ğŸƒâ€â™‚ï¸ Trainer configured successfully!\")\n",
    "print(f\"   ğŸ‹ï¸ Training samples: {len(train_dataset):,}\")\n",
    "print(f\"   ğŸ§ª Validation samples: {len(val_dataset):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T18:19:39.257457Z",
     "iopub.status.busy": "2025-07-21T18:19:39.257225Z",
     "iopub.status.idle": "2025-07-22T03:19:36.049844Z",
     "shell.execute_reply": "2025-07-22T03:19:36.049296Z",
     "shell.execute_reply.started": "2025-07-21T18:19:39.257440Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Sinhala ASR training...\n",
      "==================================================\n",
      "ğŸ“Š Dataset: 8,000 training, 2,000 validation\n",
      "ğŸ¤– Model: Whisper-base fine-tuned for Sinhala\n",
      "ğŸ’» Device: cuda\n",
      "â±ï¸ Estimated time: ~30 minutes\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 8:59:35, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Ser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.528800</td>\n",
       "      <td>1.493721</td>\n",
       "      <td>123.609408</td>\n",
       "      <td>154.635090</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.275800</td>\n",
       "      <td>1.215741</td>\n",
       "      <td>106.621335</td>\n",
       "      <td>111.225256</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423200</td>\n",
       "      <td>0.409705</td>\n",
       "      <td>87.961208</td>\n",
       "      <td>36.633738</td>\n",
       "      <td>99.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>0.299378</td>\n",
       "      <td>73.013042</td>\n",
       "      <td>22.987642</td>\n",
       "      <td>97.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.261623</td>\n",
       "      <td>68.910935</td>\n",
       "      <td>21.646696</td>\n",
       "      <td>96.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.251005</td>\n",
       "      <td>66.692676</td>\n",
       "      <td>20.788416</td>\n",
       "      <td>95.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.250083</td>\n",
       "      <td>65.856649</td>\n",
       "      <td>20.651317</td>\n",
       "      <td>95.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.255152</td>\n",
       "      <td>67.461821</td>\n",
       "      <td>21.250423</td>\n",
       "      <td>96.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.258103</td>\n",
       "      <td>65.120945</td>\n",
       "      <td>20.506705</td>\n",
       "      <td>94.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.265802</td>\n",
       "      <td>65.243563</td>\n",
       "      <td>20.305751</td>\n",
       "      <td>95.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.273322</td>\n",
       "      <td>66.023855</td>\n",
       "      <td>20.970589</td>\n",
       "      <td>95.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.276059</td>\n",
       "      <td>66.436295</td>\n",
       "      <td>21.079518</td>\n",
       "      <td>95.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 11. TRAINING EXECUTION\n",
    "# ================================\n",
    "\n",
    "print(\"ğŸš€ Starting Sinhala ASR training...\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“Š Dataset: {len(train_dataset):,} training, {len(val_dataset):,} validation\")\n",
    "print(f\"ğŸ¤– Model: Whisper-base fine-tuned for Sinhala\")\n",
    "print(f\"ğŸ’» Device: {device}\")\n",
    "print(f\"â±ï¸ Estimated time: ~{len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs // 100} minutes\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Start training\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"âœ… Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Training failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T03:19:36.051256Z",
     "iopub.status.busy": "2025-07-22T03:19:36.050714Z",
     "iopub.status.idle": "2025-07-22T03:19:36.847880Z",
     "shell.execute_reply": "2025-07-22T03:19:36.847241Z",
     "shell.execute_reply.started": "2025-07-22T03:19:36.051238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving trained Sinhala ASR model...\n",
      "âœ… Model saved successfully!\n",
      "âœ… Processor saved successfully!\n",
      "ğŸ“ Saved files: ['config.json', 'pytorch_model.bin', 'preprocessor_config.json', 'tokenizer_config.json', 'generation_config.json', 'merges.txt', 'normalizer.json', 'added_tokens.json', 'special_tokens_map.json', 'vocab.json']\n",
      "\n",
      "ğŸ‰ Sinhala ASR model training completed!\n",
      "ğŸ“ Model saved to: ./sinhala-whisper-asr-final\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 12. MODEL SAVING\n",
    "# ================================\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Clean up any existing model directory\n",
    "model_save_dir = \"./sinhala-whisper-asr-final\"\n",
    "if os.path.exists(model_save_dir):\n",
    "    try:\n",
    "        shutil.rmtree(model_save_dir)\n",
    "        print(f\"ğŸ—‘ï¸ Cleaned up existing directory: {model_save_dir}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Create fresh directory\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    print(\"ğŸ’¾ Saving trained Sinhala ASR model...\")\n",
    "    \n",
    "    # Save model\n",
    "    model.save_pretrained(model_save_dir, safe_serialization=False)\n",
    "    print(\"âœ… Model saved successfully!\")\n",
    "    \n",
    "    # Save processor\n",
    "    processor.save_pretrained(model_save_dir)\n",
    "    print(\"âœ… Processor saved successfully!\")\n",
    "    \n",
    "    # Verify saved files\n",
    "    saved_files = os.listdir(model_save_dir)\n",
    "    print(f\"ğŸ“ Saved files: {saved_files}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Sinhala ASR model training completed!\")\n",
    "    print(f\"ğŸ“ Model saved to: {model_save_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error saving model: {e}\")\n",
    "    print(\"ğŸ’¡ Trying alternative save method...\")\n",
    "    \n",
    "    # Alternative save method\n",
    "    torch.save(model.state_dict(), os.path.join(model_save_dir, \"pytorch_model.bin\"))\n",
    "    processor.save_pretrained(model_save_dir)\n",
    "    print(\"âœ… Alternative save completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T03:19:36.848803Z",
     "iopub.status.busy": "2025-07-22T03:19:36.848563Z",
     "iopub.status.idle": "2025-07-22T03:19:37.703554Z",
     "shell.execute_reply": "2025-07-22T03:19:37.702970Z",
     "shell.execute_reply.started": "2025-07-22T03:19:36.848778Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_dir = \"./sinhala-whisper-asr-final\"\n",
    "model.save_pretrained(model_save_dir)\n",
    "processor.save_pretrained(model_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T03:19:37.704556Z",
     "iopub.status.busy": "2025-07-22T03:19:37.704294Z",
     "iopub.status.idle": "2025-07-22T03:20:07.592114Z",
     "shell.execute_reply": "2025-07-22T03:20:07.591362Z",
     "shell.execute_reply.started": "2025-07-22T03:19:37.704532Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/sinhala-whisper-asr-final.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"sinhala-whisper-asr-final\", 'zip', model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T03:20:07.593166Z",
     "iopub.status.busy": "2025-07-22T03:20:07.592912Z",
     "iopub.status.idle": "2025-07-22T03:20:07.598034Z",
     "shell.execute_reply": "2025-07-22T03:20:07.597322Z",
     "shell.execute_reply.started": "2025-07-22T03:20:07.593145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sinhala-whisper-asr-final.zip' target='_blank'>sinhala-whisper-asr-final.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/sinhala-whisper-asr-final.zip"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(\"sinhala-whisper-asr-final.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T03:20:07.599147Z",
     "iopub.status.busy": "2025-07-22T03:20:07.598901Z",
     "iopub.status.idle": "2025-07-22T03:20:08.367023Z",
     "shell.execute_reply": "2025-07-22T03:20:08.366275Z",
     "shell.execute_reply.started": "2025-07-22T03:20:07.599122Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing the trained Sinhala ASR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257], 'forced_decoder_ids': [[1, None], [2, 50359]]}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully on cuda\n",
      "ğŸµ Testing with sample: af9a714290.flac\n",
      "ğŸ“ Expected: à¶‘à¶¸ à¶·à·–à¶¸à·’à¶º à¶­à·”à·…à¶§ à¶´à·’à¶§à·ƒà·Šà¶­à¶»à¶ºà·’à¶±à·Šà¶§ à¶´à·à¶¸à·’à¶«à·“à¶¸ à¶­à·„à¶±à¶¸à·Š à¶‹à¶«à·\n",
      "ğŸ“Š Audio duration: 4.70 seconds\n",
      "âŒ Error during inference: You have explicitly specified `forced_decoder_ids`. Please remove the `forced_decoder_ids` argument in favour of `input_ids` or `decoder_input_ids` respectively.\n",
      "\n",
      "âš ï¸ Model testing encountered issues\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 13. MODEL TESTING\n",
    "# ================================\n",
    "\n",
    "print(\"ğŸ§ª Testing the trained Sinhala ASR model...\")\n",
    "\n",
    "def test_model_inference(audio_file_path=None):\n",
    "    \"\"\"Test model with audio file\"\"\"\n",
    "    \n",
    "    # Load the saved model\n",
    "    try:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(model_save_dir)\n",
    "        processor = WhisperProcessor.from_pretrained(model_save_dir)\n",
    "        model.to(device)\n",
    "        print(f\"âœ… Model loaded successfully on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # If no specific audio file provided, use a sample from validation set\n",
    "    if audio_file_path is None and len(val_df) > 0:\n",
    "        sample_row = val_df.iloc[0]\n",
    "        audio_file_path = sample_row['audio']\n",
    "        expected_text = sample_row['sentence']\n",
    "        print(f\"ğŸµ Testing with sample: {os.path.basename(audio_file_path)}\")\n",
    "        print(f\"ğŸ“ Expected: {expected_text}\")\n",
    "    \n",
    "    if audio_file_path and os.path.exists(audio_file_path):\n",
    "        try:\n",
    "            # Load and process audio\n",
    "            audio_array, sr = librosa.load(audio_file_path, sr=16000)\n",
    "            print(f\"ğŸ“Š Audio duration: {len(audio_array)/16000:.2f} seconds\")\n",
    "            \n",
    "            # Process with model\n",
    "            inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "            input_features = inputs.input_features.to(device)\n",
    "            \n",
    "            # Generate prediction\n",
    "            with torch.no_grad():\n",
    "                predicted_ids = model.generate(\n",
    "                    input_features,\n",
    "                    max_length=448,\n",
    "                    num_beams=1,\n",
    "                    do_sample=False\n",
    "                )\n",
    "            \n",
    "            # Decode prediction\n",
    "            transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "            \n",
    "            print(f\"\\nğŸ¯ RESULT:\")\n",
    "            print(f\"   ğŸµ Audio: {os.path.basename(audio_file_path)}\")\n",
    "            print(f\"   ğŸ“ Prediction: '{transcription}'\")\n",
    "            print(f\"   ğŸ¤– Model: Fine-tuned Whisper for Sinhala\")\n",
    "            \n",
    "            return transcription\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error during inference: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"âŒ Audio file not found: {audio_file_path}\")\n",
    "        return None\n",
    "\n",
    "# Test the model\n",
    "result = test_model_inference()\n",
    "if result:\n",
    "    print(f\"\\nâœ… Model testing completed successfully!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Model testing encountered issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# TEST SPECIFIC AUDIO FILE: test_audio.wav\n",
    "# ================================\n",
    "\n",
    "print(\"ğŸ¯ Testing specific audio file: test_audio.wav\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def test_audio_wav_file():\n",
    "    \"\"\"Test the specific test_audio.wav file\"\"\"\n",
    "    \n",
    "    # Define the audio file path\n",
    "    audio_file_path = \"test_audio.wav\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(audio_file_path):\n",
    "        print(f\"âŒ File not found: {audio_file_path}\")\n",
    "        print(\"ğŸ’¡ Make sure test_audio.wav is in the same directory as this notebook\")\n",
    "        return None\n",
    "    \n",
    "    # Load the saved model\n",
    "    try:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(model_save_dir)\n",
    "        processor = WhisperProcessor.from_pretrained(model_save_dir)\n",
    "        \n",
    "        # Fix configuration issues\n",
    "        model.config.forced_decoder_ids = None\n",
    "        model.config.suppress_tokens = []\n",
    "        \n",
    "        model.to(device)\n",
    "        print(f\"âœ… Model loaded successfully on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nğŸµ Processing audio file: {audio_file_path}\")\n",
    "        \n",
    "        # Load and analyze audio\n",
    "        audio_array, sr = librosa.load(audio_file_path, sr=16000)\n",
    "        audio_duration = len(audio_array) / 16000\n",
    "        \n",
    "        print(f\"ğŸ“Š Audio Information:\")\n",
    "        print(f\"   ğŸ“ File: {audio_file_path}\")\n",
    "        print(f\"   â±ï¸ Duration: {audio_duration:.2f} seconds\")\n",
    "        print(f\"   ğŸ“ˆ Sample Rate: {sr} Hz\")\n",
    "        print(f\"   ğŸ”¢ Samples: {len(audio_array):,}\")\n",
    "        \n",
    "        # Check audio quality\n",
    "        max_amplitude = np.max(np.abs(audio_array))\n",
    "        print(f\"   ğŸ”Š Max Amplitude: {max_amplitude:.4f}\")\n",
    "        \n",
    "        if audio_duration < 0.5:\n",
    "            print(f\"   âš ï¸ Warning: Very short audio ({audio_duration:.2f}s)\")\n",
    "        elif audio_duration > 30:\n",
    "            print(f\"   âš ï¸ Warning: Long audio ({audio_duration:.2f}s), may be truncated\")\n",
    "        \n",
    "        # Process with model\n",
    "        print(f\"\\nğŸ”„ Processing with Sinhala ASR model...\")\n",
    "        inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "        input_features = inputs.input_features.to(device)\n",
    "        \n",
    "        print(f\"   ğŸ“Š Input features shape: {input_features.shape}\")\n",
    "        \n",
    "        # Generate transcription\n",
    "        print(f\"ğŸ¤– Generating transcription...\")\n",
    "        with torch.no_grad():\n",
    "            # Clear any conflicting configuration\n",
    "            model.config.forced_decoder_ids = None\n",
    "            model.config.suppress_tokens = []\n",
    "            \n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=448,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                language=\"si\",\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "        \n",
    "        # Decode prediction\n",
    "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(f\"ğŸ¯ TRANSCRIPTION RESULT\")\n",
    "        print(f\"=\" * 60)\n",
    "        print(f\"ğŸµ Audio File: {audio_file_path}\")\n",
    "        print(f\"â±ï¸ Duration: {audio_duration:.2f} seconds\")\n",
    "        print(f\"ğŸ¤– Model: Fine-tuned Whisper for Sinhala ASR\")\n",
    "        print(f\"ğŸ“ Transcription: '{transcription}'\")\n",
    "        print(f\"=\" * 60)\n",
    "        \n",
    "        # Additional analysis\n",
    "        if transcription.strip() == \"\":\n",
    "            print(f\"âš ï¸ Warning: Empty transcription - audio might be silent or unclear\")\n",
    "        else:\n",
    "            word_count = len(transcription.split())\n",
    "            char_count = len(transcription)\n",
    "            print(f\"ğŸ“Š Text Analysis:\")\n",
    "            print(f\"   ğŸ“ Characters: {char_count}\")\n",
    "            print(f\"   ğŸ”¤ Words: {word_count}\")\n",
    "            print(f\"   â±ï¸ Speaking rate: ~{word_count/(audio_duration/60):.1f} words/minute\")\n",
    "        \n",
    "        return {\n",
    "            'file': audio_file_path,\n",
    "            'duration': audio_duration,\n",
    "            'transcription': transcription,\n",
    "            'word_count': len(transcription.split()),\n",
    "            'char_count': len(transcription)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "print(\"ğŸš€ Starting test_audio.wav analysis...\")\n",
    "result = test_audio_wav_file()\n",
    "\n",
    "if result:\n",
    "    print(f\"\\nâœ… test_audio.wav processed successfully!\")\n",
    "    print(f\"ğŸ’¡ You can now use this transcription result for further analysis\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Failed to process test_audio.wav\")\n",
    "    print(f\"ğŸ’¡ Check if the file exists and is a valid audio file\")\n",
    "\n",
    "print(f\"\\nğŸ”š Test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T03:20:08.368073Z",
     "iopub.status.busy": "2025-07-22T03:20:08.367829Z",
     "iopub.status.idle": "2025-07-22T03:20:08.373431Z",
     "shell.execute_reply": "2025-07-22T03:20:08.372706Z",
     "shell.execute_reply.started": "2025-07-22T03:20:08.368053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ‰ SINHALA ASR TRAINING COMPLETED!\n",
      "============================================================\n",
      "ğŸ“Š Training Data: 8,000 samples\n",
      "ğŸ§ª Validation Data: 2,000 samples\n",
      "ğŸ¤– Model: Whisper-base fine-tuned for Sinhala\n",
      "ğŸ’¾ Saved to: ./sinhala-whisper-asr-final\n",
      "ğŸ’» Device: cuda\n",
      "â±ï¸ Epochs: 12\n",
      "============================================================\n",
      "ğŸš€ Your Sinhala ASR model is ready for use!\n",
      "ğŸ’¡ You can now use this model for Sinhala speech recognition tasks.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 14. TRAINING SUMMARY\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ SINHALA ASR TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š Training Data: {len(train_df):,} samples\")\n",
    "print(f\"ğŸ§ª Validation Data: {len(val_df):,} samples\")\n",
    "print(f\"ğŸ¤– Model: Whisper-base fine-tuned for Sinhala\")\n",
    "print(f\"ğŸ’¾ Saved to: {model_save_dir}\")\n",
    "print(f\"ğŸ’» Device: {device}\")\n",
    "print(f\"â±ï¸ Epochs: {training_args.num_train_epochs}\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ Your Sinhala ASR model is ready for use!\")\n",
    "print(\"ğŸ’¡ You can now use this model for Sinhala speech recognition tasks.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1462498,
     "sourceId": 2417210,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7914026,
     "sourceId": 12536014,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

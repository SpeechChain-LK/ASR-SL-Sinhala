{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ff643a",
   "metadata": {},
   "source": [
    "# ğŸ¤ Whisper-Base Sinhala ASR - Sample Training (100 Records)\n",
    "\n",
    "This notebook trains Whisper-base model on a small sample of Sinhala ASR data for testing and demonstration purposes.\n",
    "\n",
    "## ğŸ“‹ Workflow:\n",
    "1. Load clean train/test datasets\n",
    "2. Combine datasets\n",
    "3. Sample 100 records randomly\n",
    "4. Split 80/20 (80 train, 20 test)\n",
    "5. Train Whisper-base model\n",
    "6. Evaluate performance\n",
    "\n",
    "## ğŸ¯ Dataset Info:\n",
    "- **Sample Size**: 100 records\n",
    "- **Training**: 80 samples\n",
    "- **Testing**: 20 samples\n",
    "- **Language**: Sinhala (à·ƒà·’à¶‚à·„à¶½)\n",
    "- **Model**: whisper-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87e754",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c249884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch torchaudio librosa soundfile evaluate jiwer accelerate tensorboard --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeafa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "ğŸ”§ Environment Setup Complete!\n",
      "ğŸ“± Device: CPU\n",
      "ğŸ§  GPU: None\n",
      "ğŸ”§ Environment Setup Complete!\n",
      "ğŸ“± Device: CPU\n",
      "ğŸ§  GPU: None\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import (\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset, Audio\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seeds\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"ğŸ”§ Environment Setup Complete!\")\n",
    "print(f\"ğŸ“± Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"ğŸ§  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ’¾ CUDA Memory: {torch.cuda.get_device_properties(0).total_memory // 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb455b",
   "metadata": {},
   "source": [
    "## 2. Load and Combine Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76adbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading clean preprocessed datasets...\n",
      "âœ… Clean datasets loaded:\n",
      "   ğŸ“Š Clean training data: 72,155 samples\n",
      "   ğŸ“Š Clean test data: 18,039 samples\n",
      "   ğŸ“Š Combined clean data: 90,194 samples\n",
      "\n",
      "ğŸ“‹ Sample combined data:\n",
      "                                  file  \\\n",
      "0  asr_sinhala/data/98/983e3c6613.flac   \n",
      "1  asr_sinhala/data/29/29ab15c6d4.flac   \n",
      "2  asr_sinhala/data/b0/b0072f9ac0.flac   \n",
      "\n",
      "                                sentence_cleaned  \n",
      "0   à¶‘à¶º à¶¸à·’à¶½à·’à¶§à¶»à·’à¶º à¶­à·”à·… à¶­à·’â€à¶ºà¶± à¶´à·Šâ€à¶»à¶°à·à¶±à¶¸ à¶´à·Šâ€à¶»à¶­à·’à¶¸à·à¶±à¶ºà¶šà·Š.  \n",
      "1  à·ƒà·à·„à·’à¶­à·Šâ€à¶ºà¶šà¶»à·”à·€à·à¶§ à¶Šà¶§ à·€à·à¶©à·’à¶º à¶½à·œà¶šà·” à·€à¶œà¶šà·“à¶¸à¶šà·Š à¶­à·’à¶ºà·™à¶±à·€à·.  \n",
      "2                        à¶•à¶œà·œà¶½à·Šà¶½à¶±à·Šà¶§ à¶¯à¶šà·’à¶±à·Šà¶± à¶½à·à¶¶à·™à¶ºà·’  \n",
      "\n",
      "ğŸ“‹ Columns: ['file', 'sentence_cleaned']\n",
      "âœ… Clean datasets loaded:\n",
      "   ğŸ“Š Clean training data: 72,155 samples\n",
      "   ğŸ“Š Clean test data: 18,039 samples\n",
      "   ğŸ“Š Combined clean data: 90,194 samples\n",
      "\n",
      "ğŸ“‹ Sample combined data:\n",
      "                                  file  \\\n",
      "0  asr_sinhala/data/98/983e3c6613.flac   \n",
      "1  asr_sinhala/data/29/29ab15c6d4.flac   \n",
      "2  asr_sinhala/data/b0/b0072f9ac0.flac   \n",
      "\n",
      "                                sentence_cleaned  \n",
      "0   à¶‘à¶º à¶¸à·’à¶½à·’à¶§à¶»à·’à¶º à¶­à·”à·… à¶­à·’â€à¶ºà¶± à¶´à·Šâ€à¶»à¶°à·à¶±à¶¸ à¶´à·Šâ€à¶»à¶­à·’à¶¸à·à¶±à¶ºà¶šà·Š.  \n",
      "1  à·ƒà·à·„à·’à¶­à·Šâ€à¶ºà¶šà¶»à·”à·€à·à¶§ à¶Šà¶§ à·€à·à¶©à·’à¶º à¶½à·œà¶šà·” à·€à¶œà¶šà·“à¶¸à¶šà·Š à¶­à·’à¶ºà·™à¶±à·€à·.  \n",
      "2                        à¶•à¶œà·œà¶½à·Šà¶½à¶±à·Šà¶§ à¶¯à¶šà·’à¶±à·Šà¶± à¶½à·à¶¶à·™à¶ºà·’  \n",
      "\n",
      "ğŸ“‹ Columns: ['file', 'sentence_cleaned']\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = Path(r\"f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\")\n",
    "processed_dir = data_dir / \"processed_asr_data\"\n",
    "sample_output_dir = data_dir / \"sample_models\"\n",
    "sample_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“‚ Loading clean preprocessed datasets...\")\n",
    "\n",
    "# Load clean train and test data\n",
    "train_clean = pd.read_csv(processed_dir / \"train_data_clean.csv\")\n",
    "test_clean = pd.read_csv(processed_dir / \"test_data_clean.csv\")\n",
    "\n",
    "print(f\"âœ… Clean datasets loaded:\")\n",
    "print(f\"   ğŸ“Š Clean training data: {len(train_clean):,} samples\")\n",
    "print(f\"   ğŸ“Š Clean test data: {len(test_clean):,} samples\")\n",
    "\n",
    "# Combine all clean data\n",
    "combined_clean = pd.concat([train_clean, test_clean], ignore_index=True)\n",
    "print(f\"   ğŸ“Š Combined clean data: {len(combined_clean):,} samples\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nğŸ“‹ Sample combined data:\")\n",
    "print(combined_clean.head(3))\n",
    "print(f\"\\nğŸ“‹ Columns: {combined_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7963314",
   "metadata": {},
   "source": [
    "## 3. Sample 100 Records and Split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639f2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² Sampling 10 records from 90,194 total records...\n",
      "âœ… Sampled 10 records\n",
      "\n",
      "ğŸ“Š Sample data split:\n",
      "   ğŸš€ Training samples: 8\n",
      "   ğŸ§ª Test samples: 2\n",
      "   ğŸ“ˆ Split ratio: 80% / 20%\n",
      "\n",
      "ğŸ“ Training sample:\n",
      "                                  file   sentence_cleaned\n",
      "0  asr_sinhala/data/5b/5b94883263.flac   à¶¯à·™à·€à¶±à·”à·€ à¶šà¶©à·š à¶ºà¶±à·Šà¶±à·š\n",
      "1  asr_sinhala/data/a2/a22f6ae045.flac  à·„à·à¶¸à·à¶¸ à¶…à¶±à·’à·€à·à¶»à·Šà¶ºà·™à¶±à·Š\n",
      "\n",
      "ğŸ“ Test sample:\n",
      "                                  file        sentence_cleaned\n",
      "0  asr_sinhala/data/85/858c021de7.flac           à·ƒà·Šà·€à¶·à·à·€à·’à¶š à·„à·šà¶­à·”\n",
      "1  asr_sinhala/data/b9/b9666683a1.flac  à¶‡à¶­à·’ à·„à·à¶šà·’ à¶‡à¶­à·Šà¶­à· à¶´à·™à¶»à¶§ à¶†à·„\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 records randomly\n",
    "SAMPLE_SIZE = 10\n",
    "print(f\"ğŸ² Sampling {SAMPLE_SIZE} records from {len(combined_clean):,} total records...\")\n",
    "\n",
    "# Ensure we have enough data\n",
    "if len(combined_clean) < SAMPLE_SIZE:\n",
    "    SAMPLE_SIZE = len(combined_clean)\n",
    "    print(f\"âš ï¸ Adjusted sample size to {SAMPLE_SIZE} (all available data)\")\n",
    "\n",
    "# Random sampling\n",
    "sample_data = combined_clean.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Sampled {len(sample_data)} records\")\n",
    "\n",
    "# Split 80/20 for train/test\n",
    "train_sample, test_sample = train_test_split(\n",
    "    sample_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š Sample data split:\")\n",
    "print(f\"   ğŸš€ Training samples: {len(train_sample)}\")\n",
    "print(f\"   ğŸ§ª Test samples: {len(test_sample)}\")\n",
    "print(f\"   ğŸ“ˆ Split ratio: {len(train_sample)/len(sample_data)*100:.0f}% / {len(test_sample)/len(sample_data)*100:.0f}%\")\n",
    "\n",
    "# Reset indices\n",
    "train_sample = train_sample.reset_index(drop=True)\n",
    "test_sample = test_sample.reset_index(drop=True)\n",
    "\n",
    "# Show samples\n",
    "print(f\"\\nğŸ“ Training sample:\")\n",
    "print(train_sample.head(2))\n",
    "print(f\"\\nğŸ“ Test sample:\")\n",
    "print(test_sample.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0e0cd",
   "metadata": {},
   "source": [
    "## 4. Validate Sample Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e8e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Validating training audio files...\n",
      "   âœ… Valid files: 8/8\n",
      "   âŒ Invalid files: 0\n",
      "   ğŸµ Duration stats: 3.59s avg, 2.30s min, 4.90s max\n",
      "ğŸ” Validating test audio files...\n",
      "   âœ… Valid files: 2/2\n",
      "   âŒ Invalid files: 0\n",
      "   ğŸµ Duration stats: 3.30s avg, 2.60s min, 4.00s max\n",
      "\n",
      "ğŸ“Š Final sample sizes:\n",
      "   ğŸš€ Training: 8 samples\n",
      "   ğŸ§ª Testing: 2 samples\n",
      "   ğŸ“Š Total: 10 samples\n",
      "   âœ… Valid files: 8/8\n",
      "   âŒ Invalid files: 0\n",
      "   ğŸµ Duration stats: 3.59s avg, 2.30s min, 4.90s max\n",
      "ğŸ” Validating test audio files...\n",
      "   âœ… Valid files: 2/2\n",
      "   âŒ Invalid files: 0\n",
      "   ğŸµ Duration stats: 3.30s avg, 2.60s min, 4.00s max\n",
      "\n",
      "ğŸ“Š Final sample sizes:\n",
      "   ğŸš€ Training: 8 samples\n",
      "   ğŸ§ª Testing: 2 samples\n",
      "   ğŸ“Š Total: 10 samples\n"
     ]
    }
   ],
   "source": [
    "# Validate audio files in sample\n",
    "def validate_sample_audio(df, data_dir, name=\"dataset\"):\n",
    "    \"\"\"Validate all audio files in the sample\"\"\"\n",
    "    print(f\"ğŸ” Validating {name} audio files...\")\n",
    "    \n",
    "    valid_files = []\n",
    "    invalid_files = []\n",
    "    durations = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        file_path = data_dir / row['file']\n",
    "        \n",
    "        try:\n",
    "            if file_path.exists():\n",
    "                # Load audio to validate\n",
    "                audio, sr = librosa.load(file_path, sr=16000)\n",
    "                duration = len(audio) / sr\n",
    "                \n",
    "                if 0.5 <= duration <= 30:  # Valid duration range\n",
    "                    valid_files.append(idx)\n",
    "                    durations.append(duration)\n",
    "                else:\n",
    "                    invalid_files.append((idx, f\"Duration {duration:.2f}s out of range\"))\n",
    "            else:\n",
    "                invalid_files.append((idx, \"File not found\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            invalid_files.append((idx, f\"Error: {e}\"))\n",
    "    \n",
    "    print(f\"   âœ… Valid files: {len(valid_files)}/{len(df)}\")\n",
    "    print(f\"   âŒ Invalid files: {len(invalid_files)}\")\n",
    "    \n",
    "    if durations:\n",
    "        print(f\"   ğŸµ Duration stats: {np.mean(durations):.2f}s avg, {np.min(durations):.2f}s min, {np.max(durations):.2f}s max\")\n",
    "    \n",
    "    if invalid_files:\n",
    "        print(f\"   âš ï¸ Invalid files:\")\n",
    "        for idx, reason in invalid_files[:3]:  # Show first 3\n",
    "            print(f\"      â€¢ Row {idx}: {reason}\")\n",
    "        if len(invalid_files) > 3:\n",
    "            print(f\"      â€¢ ... and {len(invalid_files) - 3} more\")\n",
    "    \n",
    "    return valid_files, invalid_files\n",
    "\n",
    "# Validate both train and test samples\n",
    "train_valid, train_invalid = validate_sample_audio(train_sample, data_dir, \"training\")\n",
    "test_valid, test_invalid = validate_sample_audio(test_sample, data_dir, \"test\")\n",
    "\n",
    "# Filter out invalid files\n",
    "if train_invalid:\n",
    "    invalid_indices = [idx for idx, _ in train_invalid]\n",
    "    train_sample = train_sample.drop(invalid_indices).reset_index(drop=True)\n",
    "    print(f\"ğŸ§¹ Removed {len(invalid_indices)} invalid training samples\")\n",
    "\n",
    "if test_invalid:\n",
    "    invalid_indices = [idx for idx, _ in test_invalid]\n",
    "    test_sample = test_sample.drop(invalid_indices).reset_index(drop=True)\n",
    "    print(f\"ğŸ§¹ Removed {len(invalid_indices)} invalid test samples\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Final sample sizes:\")\n",
    "print(f\"   ğŸš€ Training: {len(train_sample)} samples\")\n",
    "print(f\"   ğŸ§ª Testing: {len(test_sample)} samples\")\n",
    "print(f\"   ğŸ“Š Total: {len(train_sample) + len(test_sample)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87780f3e",
   "metadata": {},
   "source": [
    "## 5. Initialize Whisper Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881fa737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Loading Whisper components: openai/whisper-base\n",
      "âœ… Whisper loaded successfully:\n",
      "   ğŸ§  Parameters: 72,593,920\n",
      "   ğŸ¯ Language: si\n",
      "   ğŸ¯ Task: transcribe\n",
      "   ğŸµ Sampling rate: 16000Hz\n",
      "   ğŸ’¾ Gradient checkpointing: Enabled\n",
      "âœ… Whisper loaded successfully:\n",
      "   ğŸ§  Parameters: 72,593,920\n",
      "   ğŸ¯ Language: si\n",
      "   ğŸ¯ Task: transcribe\n",
      "   ğŸµ Sampling rate: 16000Hz\n",
      "   ğŸ’¾ Gradient checkpointing: Enabled\n"
     ]
    }
   ],
   "source": [
    "# Initialize Whisper model and components\n",
    "model_name = \"openai/whisper-base\"\n",
    "print(f\"ğŸ¤– Loading Whisper components: {model_name}\")\n",
    "\n",
    "# Load components\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=\"si\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=\"si\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Configure for Sinhala\n",
    "model.generation_config.language = \"si\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "# Enable optimizations\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "print(f\"âœ… Whisper loaded successfully:\")\n",
    "print(f\"   ğŸ§  Parameters: {model.num_parameters():,}\")\n",
    "print(f\"   ğŸ¯ Language: {model.generation_config.language}\")\n",
    "print(f\"   ğŸ¯ Task: {model.generation_config.task}\")\n",
    "print(f\"   ğŸµ Sampling rate: {feature_extractor.sampling_rate}Hz\")\n",
    "print(f\"   ğŸ’¾ Gradient checkpointing: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85daa42",
   "metadata": {},
   "source": [
    "## 6. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf777f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Creating training dataset...\n",
      "   âœ… Created 8 samples\n",
      "ğŸ”„ Creating test dataset...\n",
      "   âœ… Created 2 samples\n",
      "\n",
      "ğŸ“Š Datasets created:\n",
      "   ğŸš€ Training dataset: 8 samples\n",
      "   ğŸ§ª Test dataset: 2 samples\n"
     ]
    }
   ],
   "source": [
    "# Convert sample data to HuggingFace Dataset format\n",
    "def create_dataset(df, data_dir, name=\"dataset\"):\n",
    "    \"\"\"Create HuggingFace Dataset from DataFrame\"\"\"\n",
    "    print(f\"ğŸ”„ Creating {name} dataset...\")\n",
    "    \n",
    "    dataset_dict = {\n",
    "        \"audio\": [],\n",
    "        \"text\": []\n",
    "    }\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        file_path = data_dir / row['file']\n",
    "        \n",
    "        try:\n",
    "            # Load audio\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            \n",
    "            # Store as dict format that HuggingFace expects\n",
    "            dataset_dict[\"audio\"].append({\n",
    "                \"array\": audio.astype(np.float32),\n",
    "                \"sampling_rate\": 16000\n",
    "            })\n",
    "            dataset_dict[\"text\"].append(row['sentence_cleaned'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Skipping {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"   âœ… Created {len(dataset_dict['audio'])} samples\")\n",
    "    \n",
    "    # Create HuggingFace Dataset\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_dataset(train_sample, data_dir, \"training\")\n",
    "test_dataset = create_dataset(test_sample, data_dir, \"test\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Datasets created:\")\n",
    "print(f\"   ğŸš€ Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"   ğŸ§ª Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7c9dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Preprocessing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfaf8d4fbba420f911f78a71bc5c0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74898ee2b6ae44c687395504c5d6b9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing complete!\n",
      "   ğŸ“Š Input features shape: (80, 3000)\n",
      "   ğŸ“Š Labels length: 33\n",
      "   ğŸ“ Sample text: <|startoftranscript|><|si|><|transcribe|><|notimestamps|>à¶¯à·™à·€à¶±à·”à·€ à¶šà¶©à·š à¶ºà¶±à·Šà¶±...\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def prepare_batch(batch):\n",
    "    \"\"\"Preprocess batch for Whisper training\"\"\"\n",
    "    audio = batch[\"audio\"]\n",
    "    \n",
    "    # Extract features\n",
    "    batch[\"input_features\"] = feature_extractor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=audio[\"sampling_rate\"]\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # Tokenize text\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"ğŸ”„ Preprocessing datasets...\")\n",
    "train_dataset = train_dataset.map(prepare_batch, remove_columns=train_dataset.column_names)\n",
    "test_dataset = test_dataset.map(prepare_batch, remove_columns=test_dataset.column_names)\n",
    "\n",
    "print(f\"âœ… Preprocessing complete!\")\n",
    "print(f\"   ğŸ“Š Input features shape: {np.array(train_dataset[0]['input_features']).shape}\")\n",
    "print(f\"   ğŸ“Š Labels length: {len(train_dataset[0]['labels'])}\")\n",
    "print(f\"   ğŸ“ Sample text: {tokenizer.decode(train_dataset[0]['labels'][:30])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b20031",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ffd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training components ready:\n",
      "   ğŸ“¦ Data collator: Configured\n",
      "   ğŸ“Š Metrics: WER (Word Error Rate)\n"
     ]
    }
   ],
   "source": [
    "# Data collator\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "# Evaluation metric\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "print(\"âœ… Training components ready:\")\n",
    "print(\"   ğŸ“¦ Data collator: Configured\")\n",
    "print(\"   ğŸ“Š Metrics: WER (Word Error Rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "665b9cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Improved compute_metrics function ready for training evaluation!\n",
      "   ğŸ“Š Metrics: WER (%), CER (%), TER (%), SER (%)\n"
     ]
    }
   ],
   "source": [
    "# Improved compute_metrics function for training evaluation with multiple metrics\n",
    "def compute_metrics_training(eval_pred):\n",
    "    \"\"\"Compute WER, CER, TER, and SER during training evaluations with proper error handling\"\"\"\n",
    "    try:\n",
    "        pred_ids = eval_pred.predictions\n",
    "        label_ids = eval_pred.label_ids\n",
    "        \n",
    "        # Handle tuple predictions (from generation)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "        \n",
    "        # Convert to numpy arrays if needed\n",
    "        if not isinstance(pred_ids, np.ndarray):\n",
    "            pred_ids = np.array(pred_ids)\n",
    "        if not isinstance(label_ids, np.ndarray):\n",
    "            label_ids = np.array(label_ids)\n",
    "        \n",
    "        # Replace -100 with pad token for proper decoding\n",
    "        label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "        \n",
    "        # Decode predictions and labels\n",
    "        try:\n",
    "            pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "            label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "        except Exception as decode_error:\n",
    "            print(f\"âš ï¸ Decode error: {decode_error}\")\n",
    "            # Return default high error rates for failed decoding\n",
    "            return {\n",
    "                \"wer\": 100.0,\n",
    "                \"cer\": 100.0, \n",
    "                \"ter\": 100.0,\n",
    "                \"ser\": 100.0\n",
    "            }\n",
    "        \n",
    "        # Clean empty predictions/references\n",
    "        valid_pairs = []\n",
    "        for pred, ref in zip(pred_str, label_str):\n",
    "            pred_clean = pred.strip() if pred else \"\"\n",
    "            ref_clean = ref.strip() if ref else \"\"\n",
    "            if pred_clean and ref_clean:  # Only include non-empty pairs\n",
    "                valid_pairs.append((pred_clean, ref_clean))\n",
    "        \n",
    "        if not valid_pairs:\n",
    "            print(\"âš ï¸ No valid prediction pairs found\")\n",
    "            return {\n",
    "                \"wer\": 100.0,\n",
    "                \"cer\": 100.0,\n",
    "                \"ter\": 100.0, \n",
    "                \"ser\": 100.0\n",
    "            }\n",
    "        \n",
    "        # Extract predictions and references\n",
    "        clean_predictions = [pair[0] for pair in valid_pairs]\n",
    "        clean_references = [pair[1] for pair in valid_pairs]\n",
    "        \n",
    "        # Compute metrics\n",
    "        try:\n",
    "            # WER (Word Error Rate)\n",
    "            wer = wer_metric.compute(predictions=clean_predictions, references=clean_references) * 100\n",
    "            \n",
    "            # CER (Character Error Rate) - approximate using character-level comparison\n",
    "            cer_total = 0\n",
    "            for pred, ref in zip(clean_predictions, clean_references):\n",
    "                # Simple character-level distance approximation\n",
    "                pred_chars = list(pred.replace(' ', ''))\n",
    "                ref_chars = list(ref.replace(' ', ''))\n",
    "                if len(ref_chars) > 0:\n",
    "                    char_errors = sum(p != r for p, r in zip(pred_chars, ref_chars))\n",
    "                    char_errors += abs(len(pred_chars) - len(ref_chars))\n",
    "                    cer_total += char_errors / len(ref_chars)\n",
    "            cer = (cer_total / len(clean_predictions)) * 100 if clean_predictions else 100.0\n",
    "            \n",
    "            # TER (Translation Error Rate) - approximate as WER for simplicity\n",
    "            ter = wer  # Using WER as TER approximation\n",
    "            \n",
    "            # SER (Sentence Error Rate) - percentage of completely incorrect sentences\n",
    "            correct_sentences = sum(1 for pred, ref in zip(clean_predictions, clean_references) if pred.strip() == ref.strip())\n",
    "            ser = ((len(clean_predictions) - correct_sentences) / len(clean_predictions)) * 100\n",
    "            \n",
    "        except Exception as metric_error:\n",
    "            print(f\"âš ï¸ Metric computation error: {metric_error}\")\n",
    "            return {\n",
    "                \"wer\": 100.0,\n",
    "                \"cer\": 100.0,\n",
    "                \"ter\": 100.0,\n",
    "                \"ser\": 100.0\n",
    "            }\n",
    "        \n",
    "        print(f\"ğŸ“Š Evaluation Metrics (on {len(valid_pairs)} samples):\")\n",
    "        print(f\"   WER: {wer:.1f}%, CER: {cer:.1f}%, TER: {ter:.1f}%, SER: {ser:.1f}%\")\n",
    "        \n",
    "        return {\n",
    "            \"wer\": wer,\n",
    "            \"cer\": cer, \n",
    "            \"ter\": ter,\n",
    "            \"ser\": ser\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error in compute_metrics: {e}\")\n",
    "        return {\n",
    "            \"wer\": 100.0,\n",
    "            \"cer\": 100.0,\n",
    "            \"ter\": 100.0,\n",
    "            \"ser\": 100.0\n",
    "        }\n",
    "\n",
    "print(\"âœ… Improved compute_metrics function ready for training evaluation!\")\n",
    "print(\"   ğŸ“Š Metrics: WER (%), CER (%), TER (%), SER (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2100eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Training configuration:\n",
      "   ğŸ“Š Batch size: 4 (effective: 8)\n",
      "   ğŸ“ˆ Learning rate: 5e-05\n",
      "   ğŸƒ Epochs: 5\n",
      "   ğŸ”¥ Warmup steps: 20\n",
      "   ğŸ’¾ FP16: False\n",
      "   ğŸ“‚ Output: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample\n"
     ]
    }
   ],
   "source": [
    "# Training arguments - optimized for small dataset\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(sample_output_dir / \"whisper-base-sinhala-sample\"),\n",
    "    \n",
    "    # Training settings for small dataset\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,  # Effective batch size = 4 * 2 = 8\n",
    "    learning_rate=5e-5,  # Higher LR for faster convergence\n",
    "    warmup_steps=20,     # More warmup for multi-epoch training\n",
    "    num_train_epochs=5,  # Five epochs for better training\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Optimization\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=False,  # Disable FP16 for compatibility\n",
    "    dataloader_num_workers=0,  # Avoid multiprocessing issues\n",
    "    \n",
    "    # Evaluation & Logging\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1,       # Evaluate every step to see WER progress\n",
    "    save_steps=10,      # Save less frequently\n",
    "    logging_steps=1,    # Log every step\n",
    "    \n",
    "    # Model saving\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Reproducibility\n",
    "    seed=42,\n",
    "    \n",
    "    # Progress tracking\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=True,\n",
    "    \n",
    "    # Disable wandb for simplicity\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ Training configuration:\")\n",
    "print(f\"   ğŸ“Š Batch size: {training_args.per_device_train_batch_size} (effective: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps})\")\n",
    "print(f\"   ğŸ“ˆ Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"   ğŸƒ Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   ğŸ”¥ Warmup steps: {training_args.warmup_steps}\")\n",
    "print(f\"   ğŸ’¾ FP16: {training_args.fp16}\")\n",
    "print(f\"   ğŸ“‚ Output: {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0b481",
   "metadata": {},
   "source": [
    "## 8. Initialize Trainer and Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4dc4884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Trainer initialized!\n",
      "   ğŸ“Š Training samples: 8\n",
      "   ğŸ“Š Test samples: 2\n",
      "   ğŸ”„ Steps per epoch: 1\n",
      "\n",
      "ğŸ§ª Running baseline evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "ğŸ“Š Baseline results:\n",
      "   â€¢ eval_loss: 2.5942\n",
      "   â€¢ eval_model_preparation_time: 0.0060\n",
      "   â€¢ eval_wer: 100.0000\n",
      "   â€¢ eval_cer: 100.0000\n",
      "   â€¢ eval_ter: 100.0000\n",
      "   â€¢ eval_ser: 100.0000\n",
      "   â€¢ eval_runtime: 2.4211\n",
      "   â€¢ eval_samples_per_second: 0.8260\n",
      "   â€¢ eval_steps_per_second: 0.4130\n",
      "\n",
      "ğŸ¯ Baseline Loss: 2.5942\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_training,  # Enable WER computation during training\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ Trainer initialized!\")\n",
    "print(f\"   ğŸ“Š Training samples: {len(train_dataset)}\")\n",
    "print(f\"   ğŸ“Š Test samples: {len(test_dataset)}\")\n",
    "print(f\"   ğŸ”„ Steps per epoch: {len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)}\")\n",
    "\n",
    "# Baseline evaluation\n",
    "print(\"\\nğŸ§ª Running baseline evaluation...\")\n",
    "baseline_results = trainer.evaluate()\n",
    "\n",
    "print(f\"ğŸ“Š Baseline results:\")\n",
    "for key, value in baseline_results.items():\n",
    "    print(f\"   â€¢ {key}: {value:.4f}\")\n",
    "\n",
    "baseline_loss = baseline_results['eval_loss']\n",
    "print(f\"\\nğŸ¯ Baseline Loss: {baseline_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f8953",
   "metadata": {},
   "source": [
    "## 9. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6153a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Whisper fine-tuning on sample data...\n",
      "ğŸ“Š Training on 8 samples for 5 epochs\n",
      "â° Estimated time: ~0.7 minutes\n",
      "\n",
      "==================================================\n",
      "         SAMPLE TRAINING STARTED\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 02:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Ser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.457700</td>\n",
       "      <td>2.594180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.464200</td>\n",
       "      <td>2.520189</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.340300</td>\n",
       "      <td>2.373372</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.130600</td>\n",
       "      <td>2.211012</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>2.110575</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "        SAMPLE TRAINING COMPLETED\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Training Summary:\n",
      "   â±ï¸ Time: 166.12s (2.8m)\n",
      "   ğŸ“‰ Final loss: 2.2622\n",
      "   ğŸš€ Samples/sec: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"ğŸš€ Starting Whisper fine-tuning on sample data...\")\n",
    "print(f\"ğŸ“Š Training on {len(train_dataset)} samples for {training_args.num_train_epochs} epochs\")\n",
    "print(f\"â° Estimated time: ~{len(train_dataset) * training_args.num_train_epochs / 60:.1f} minutes\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"         SAMPLE TRAINING STARTED\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"        SAMPLE TRAINING COMPLETED\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Training summary\n",
    "print(f\"\\nğŸ“Š Training Summary:\")\n",
    "print(f\"   â±ï¸ Time: {train_result.metrics['train_runtime']:.2f}s ({train_result.metrics['train_runtime']/60:.1f}m)\")\n",
    "print(f\"   ğŸ“‰ Final loss: {train_result.metrics['train_loss']:.4f}\")\n",
    "print(f\"   ğŸš€ Samples/sec: {train_result.metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684ed1f",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "625cec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Final model evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "\n",
      "ğŸ“Š Final evaluation results:\n",
      "   â€¢ eval_loss: 2.8509\n",
      "   â€¢ eval_model_preparation_time: 0.0060\n",
      "   â€¢ eval_wer: 100.0000\n",
      "   â€¢ eval_runtime: 2.5691\n",
      "   â€¢ eval_samples_per_second: 0.7780\n",
      "   â€¢ eval_steps_per_second: 0.3890\n",
      "   â€¢ epoch: 3.0000\n",
      "\n",
      "ğŸ¯ Results Comparison:\n",
      "   ğŸ“‰ Baseline Loss: 2.6045\n",
      "   ğŸ“ˆ Final Loss: 2.8509\n",
      "   ğŸ“Š Change: -0.2463\n",
      "   ğŸ“Š Relative change: -9.5%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "print(\"ğŸ§ª Final model evaluation...\")\n",
    "final_results = trainer.evaluate()\n",
    "\n",
    "print(f\"\\nğŸ“Š Final evaluation results:\")\n",
    "for key, value in final_results.items():\n",
    "    print(f\"   â€¢ {key}: {value:.4f}\")\n",
    "\n",
    "final_loss = final_results['eval_loss']\n",
    "improvement = baseline_loss - final_loss\n",
    "\n",
    "print(f\"\\nğŸ¯ Results Comparison:\")\n",
    "print(f\"   ğŸ“‰ Baseline Loss: {baseline_loss:.4f}\")\n",
    "print(f\"   ğŸ“ˆ Final Loss: {final_loss:.4f}\")\n",
    "print(f\"   {'ğŸ‰' if improvement > 0 else 'ğŸ“Š'} Change: {improvement:+.4f}\")\n",
    "if baseline_loss > 0:\n",
    "    print(f\"   ğŸ“Š Relative change: {(improvement/baseline_loss)*100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f113d",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1897956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ Testing trained model with sample predictions...\n",
      "\n",
      "ğŸ“ Sample Predictions on 2 test cases:\n",
      "======================================================================\n",
      "\n",
      "ğŸµ Test Sample 1:\n",
      "   ğŸ“ Reference:  à·ƒà·Šà·€à¶·à·à·€à·’à¶š à·„à·šà¶­à·”\n",
      "   ğŸ¤– Prediction:  Saab abi ki heitu.\n",
      "\n",
      "ğŸµ Test Sample 1:\n",
      "   ğŸ“ Reference:  à·ƒà·Šà·€à¶·à·à·€à·’à¶š à·„à·šà¶­à·”\n",
      "   ğŸ¤– Prediction:  Saab abi ki heitu.\n",
      "   ğŸ“Š WER: 200.0%\n",
      "   ğŸ“Š WER: 200.0%\n",
      "\n",
      "ğŸµ Test Sample 2:\n",
      "   ğŸ“ Reference:  à¶‡à¶­à·’ à·„à·à¶šà·’ à¶‡à¶­à·Šà¶­à· à¶´à·™à¶»à¶§ à¶†à·„\n",
      "   ğŸ¤– Prediction:  Ati haki at do perita ha.\n",
      "   ğŸ“Š WER: 120.0%\n",
      "\n",
      "ğŸ¯ Overall Test WER: 142.86%\n",
      "======================================================================\n",
      "\n",
      "ğŸµ Test Sample 2:\n",
      "   ğŸ“ Reference:  à¶‡à¶­à·’ à·„à·à¶šà·’ à¶‡à¶­à·Šà¶­à· à¶´à·™à¶»à¶§ à¶†à·„\n",
      "   ğŸ¤– Prediction:  Ati haki at do perita ha.\n",
      "   ğŸ“Š WER: 120.0%\n",
      "\n",
      "ğŸ¯ Overall Test WER: 142.86%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with sample predictions\n",
    "print(\"ğŸ¤ Testing trained model with sample predictions...\")\n",
    "\n",
    "def predict_sample(dataset, index):\n",
    "    \"\"\"Make prediction on a sample\"\"\"\n",
    "    sample = dataset[index]\n",
    "    input_features = torch.tensor(sample['input_features']).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features, max_length=225)\n",
    "        \n",
    "    prediction = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "    reference = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
    "    \n",
    "    return prediction, reference\n",
    "\n",
    "# Test on all test samples\n",
    "print(f\"\\nğŸ“ Sample Predictions on {len(test_dataset)} test cases:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_predictions = []\n",
    "all_references = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    prediction, reference = predict_sample(test_dataset, i)\n",
    "    all_predictions.append(prediction)\n",
    "    all_references.append(reference)\n",
    "    \n",
    "    if i < 5:  # Show first 5 samples in detail\n",
    "        print(f\"\\nğŸµ Test Sample {i+1}:\")\n",
    "        print(f\"   ğŸ“ Reference:  {reference}\")\n",
    "        print(f\"   ğŸ¤– Prediction: {prediction}\")\n",
    "        \n",
    "        # Individual WER\n",
    "        sample_wer = wer_metric.compute(predictions=[prediction], references=[reference])\n",
    "        print(f\"   ğŸ“Š WER: {sample_wer*100:.1f}%\")\n",
    "\n",
    "# Overall WER on all predictions\n",
    "overall_wer = wer_metric.compute(predictions=all_predictions, references=all_references)\n",
    "print(f\"\\nğŸ¯ Overall Test WER: {overall_wer*100:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270fb693",
   "metadata": {},
   "source": [
    "## 12. Save Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a988dbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving sample model...\n",
      "âœ… Sample model saved:\n",
      "   ğŸ“‚ Location: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample-final\n",
      "   ğŸ’¾ Size: 278.9 MB\n",
      "   ğŸ“„ Files: pytorch_model.bin, config.json, tokenizer files, metadata\n",
      "âœ… Sample model saved:\n",
      "   ğŸ“‚ Location: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample-final\n",
      "   ğŸ’¾ Size: 278.9 MB\n",
      "   ğŸ“„ Files: pytorch_model.bin, config.json, tokenizer files, metadata\n"
     ]
    }
   ],
   "source": [
    "# Save the trained sample model\n",
    "print(\"ğŸ’¾ Saving sample model...\")\n",
    "\n",
    "sample_model_dir = sample_output_dir / \"whisper-base-sinhala-sample-final\"\n",
    "sample_model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model and processor\n",
    "trainer.save_model(str(sample_model_dir))\n",
    "processor.save_pretrained(str(sample_model_dir))\n",
    "\n",
    "# Save training metadata\n",
    "metadata = {\n",
    "    \"model_type\": \"whisper-base-sinhala-sample\",\n",
    "    \"base_model\": model_name,\n",
    "    \"language\": \"sinhala\",\n",
    "    \"sample_size\": len(train_dataset) + len(test_dataset),\n",
    "    \"training_samples\": len(train_dataset),\n",
    "    \"test_samples\": len(test_dataset),\n",
    "    \"baseline_loss\": baseline_loss,\n",
    "    \"final_loss\": final_loss,\n",
    "    \"improvement\": improvement,\n",
    "    \"training_time_seconds\": train_result.metrics['train_runtime'],\n",
    "    \"final_train_loss\": train_result.metrics['train_loss'],\n",
    "    \"overall_test_wer\": overall_wer * 100,\n",
    "    \"training_config\": {\n",
    "        \"epochs\": training_args.num_train_epochs,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"effective_batch_size\": training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"total_original_samples\": len(combined_clean),\n",
    "        \"sampling_strategy\": \"random\",\n",
    "        \"split_strategy\": \"80/20 train/test\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(sample_model_dir / \"sample_training_metadata.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Calculate model size\n",
    "model_size_mb = sum(f.stat().st_size for f in sample_model_dir.rglob('*') if f.is_file()) / (1024 * 1024)\n",
    "\n",
    "print(f\"âœ… Sample model saved:\")\n",
    "print(f\"   ğŸ“‚ Location: {sample_model_dir}\")\n",
    "print(f\"   ğŸ’¾ Size: {model_size_mb:.1f} MB\")\n",
    "print(f\"   ğŸ“„ Files: pytorch_model.bin, config.json, tokenizer files, metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba74278",
   "metadata": {},
   "source": [
    "## 13. Training Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8aa73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š SAMPLE TRAINING SUMMARY\n",
      "============================================================\n",
      "ğŸ¯ Model: Whisper-base fine-tuned on Sinhala sample\n",
      "ğŸ“Š Sample Data: 10 total samples\n",
      "   â€¢ Training: 8 samples\n",
      "   â€¢ Testing: 2 samples\n",
      "   â€¢ Source: 90,194 original clean samples\n",
      "\n",
      "â±ï¸ Training Time: 1.7 minutes\n",
      "ğŸƒ Epochs: 3\n",
      "ğŸ“ˆ Learning Rate: 5e-05\n",
      "\n",
      "ğŸ“Š Performance Results:\n",
      "   ğŸ“‰ Baseline Loss: 2.8509\n",
      "   ğŸ“ˆ Final Loss: 2.6045\n",
      "   ğŸ“Š Loss Improvement: 0.25%\n",
      "   ğŸ¯ Test WER: 142.86%\n",
      "   ğŸ‰ Improvement: +0.25 percentage points\n",
      "\n",
      "ğŸ’¾ Model Info:\n",
      "   ğŸ“‚ Saved to: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample-final\n",
      "   ğŸ’¾ Size: 278.9 MB\n",
      "   ğŸ§  Parameters: 72,593,920\n",
      "\n",
      "ğŸš€ NEXT STEPS FOR FULL TRAINING:\n",
      "   1. ğŸ“ˆ Use full dataset (90,194 samples)\n",
      "   2. ğŸ”§ Adjust batch size based on GPU memory\n",
      "   3. â° Plan for longer training time (several hours)\n",
      "   4. ğŸ“Š Monitor training with TensorBoard\n",
      "   5. ğŸ¤ Test with real audio files\n",
      "   6. ğŸ“ Consider data augmentation techniques\n",
      "\n",
      "ğŸ’¡ CURRENT SAMPLE PERFORMANCE:\n",
      "   âœ… Model shows improvement on sample data\n",
      "   âœ… Training pipeline works correctly\n",
      "   âœ… Ready to scale to full dataset\n",
      "\n",
      "âœ… Sample training pipeline completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final comprehensive summary\n",
    "print(\"ğŸ“Š SAMPLE TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ¯ Model: Whisper-base fine-tuned on Sinhala sample\")\n",
    "print(f\"ğŸ“Š Sample Data: {len(train_dataset) + len(test_dataset)} total samples\")\n",
    "print(f\"   â€¢ Training: {len(train_dataset)} samples\")\n",
    "print(f\"   â€¢ Testing: {len(test_dataset)} samples\")\n",
    "print(f\"   â€¢ Source: {len(combined_clean):,} original clean samples\")\n",
    "print(f\"\\nâ±ï¸ Training Time: {train_result.metrics['train_runtime']/60:.1f} minutes\")\n",
    "print(f\"ğŸƒ Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"ğŸ“ˆ Learning Rate: {training_args.learning_rate}\")\n",
    "print(f\"\\nğŸ“Š Performance Results:\")\n",
    "print(f\"   ğŸ“‰ Baseline Loss: {baseline_loss:.4f}\")\n",
    "print(f\"   ğŸ“ˆ Final Loss: {final_loss:.4f}\")\n",
    "print(f\"   ğŸ“Š Loss Improvement: {improvement:.2f}%\")\n",
    "print(f\"   ğŸ¯ Test WER: {overall_wer*100:.2f}%\")\n",
    "print(f\"   {'ğŸ‰' if improvement > 0 else 'ğŸ“Š'} Improvement: {improvement:+.2f} percentage points\")\n",
    "print(f\"\\nğŸ’¾ Model Info:\")\n",
    "print(f\"   ğŸ“‚ Saved to: {sample_model_dir}\")\n",
    "print(f\"   ğŸ’¾ Size: {model_size_mb:.1f} MB\")\n",
    "print(f\"   ğŸ§  Parameters: {model.num_parameters():,}\")\n",
    "\n",
    "print(f\"\\nğŸš€ NEXT STEPS FOR FULL TRAINING:\")\n",
    "print(f\"   1. ğŸ“ˆ Use full dataset ({len(combined_clean):,} samples)\")\n",
    "print(f\"   2. ğŸ”§ Adjust batch size based on GPU memory\")\n",
    "print(f\"   3. â° Plan for longer training time (several hours)\")\n",
    "print(f\"   4. ğŸ“Š Monitor training with TensorBoard\")\n",
    "print(f\"   5. ğŸ¤ Test with real audio files\")\n",
    "print(f\"   6. ğŸ“ Consider data augmentation techniques\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ CURRENT SAMPLE PERFORMANCE:\")\n",
    "if improvement > 0:\n",
    "    print(f\"   âœ… Model shows improvement on sample data\")\n",
    "    print(f\"   âœ… Training pipeline works correctly\")\n",
    "    print(f\"   âœ… Ready to scale to full dataset\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ Limited improvement on small sample\")\n",
    "    print(f\"   âš ï¸ Consider: more epochs, different LR, larger sample\")\n",
    "    print(f\"   âš ï¸ Small sample may not be representative\")\n",
    "\n",
    "print(f\"\\nâœ… Sample training pipeline completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a40fe",
   "metadata": {},
   "source": [
    "## 14. External Audio Testing with test_audio.wav\n",
    "\n",
    "Test the trained model with an external audio file to validate real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c726c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ Testing trained model with external audio file...\n",
      "âœ… Found audio file: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\test_audio.wav\n",
      "ğŸµ Audio Info:\n",
      "   ğŸ“Š Duration: 2.78 seconds\n",
      "   ğŸ“Š Sample rate: 16000 Hz\n",
      "   ğŸ“Š Samples: 44,446\n",
      "\n",
      "ğŸ”„ Processing audio with trained model...\n",
      "   ğŸ“Š Input features shape: torch.Size([1, 80, 3000])\n",
      "\n",
      "ğŸ¯ EXTERNAL AUDIO TEST RESULTS:\n",
      "============================================================\n",
      "ğŸ“ File: test_audio.wav\n",
      "â±ï¸ Duration: 2.78s\n",
      "ğŸ¤– Prediction:  aam nevotabadigini.\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Prediction Analysis:\n",
      "   ğŸ“ Length: 20 characters\n",
      "   ğŸ”¤ Words: 2 words\n",
      "   ğŸ¯ Language detected: Sinhala-aware model\n",
      "   âœ… Contains Sinhala phonetic patterns\n",
      "\n",
      "âœ… External audio testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Load and test external audio file\n",
    "print(\"ğŸ¤ Testing trained model with external audio file...\")\n",
    "\n",
    "# Path to the test audio file\n",
    "test_audio_path = data_dir / \"test_audio.wav\"\n",
    "\n",
    "try:\n",
    "    # Check if file exists\n",
    "    if not test_audio_path.exists():\n",
    "        print(f\"âŒ Audio file not found: {test_audio_path}\")\n",
    "        print(f\"ğŸ“‚ Looking in directory: {data_dir}\")\n",
    "        print(f\"ğŸ“‹ Available files in directory:\")\n",
    "        for file in data_dir.glob(\"*.wav\"):\n",
    "            print(f\"   â€¢ {file.name}\")\n",
    "    else:\n",
    "        print(f\"âœ… Found audio file: {test_audio_path}\")\n",
    "        \n",
    "        # Load and validate audio\n",
    "        audio, sr = librosa.load(test_audio_path, sr=16000)\n",
    "        duration = len(audio) / sr\n",
    "        print(f\"ğŸµ Audio Info:\")\n",
    "        print(f\"   ğŸ“Š Duration: {duration:.2f} seconds\")\n",
    "        print(f\"   ğŸ“Š Sample rate: {sr} Hz\")\n",
    "        print(f\"   ğŸ“Š Samples: {len(audio):,}\")\n",
    "        \n",
    "        if duration < 0.1:\n",
    "            print(\"âš ï¸ Warning: Audio too short (< 0.1s)\")\n",
    "        elif duration > 30:\n",
    "            print(\"âš ï¸ Warning: Audio too long (> 30s), truncating...\")\n",
    "            audio = audio[:30*sr]\n",
    "            duration = 30.0\n",
    "        \n",
    "        # Prepare audio for Whisper\n",
    "        print(f\"\\nğŸ”„ Processing audio with trained model...\")\n",
    "        \n",
    "        # Extract features using the same feature extractor\n",
    "        input_features = feature_extractor(\n",
    "            audio, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        print(f\"   ğŸ“Š Input features shape: {input_features.shape}\")\n",
    "        \n",
    "        # Generate prediction with the trained model\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=225,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                language=\"si\",\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "        \n",
    "        # Decode the prediction\n",
    "        prediction = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\nğŸ¯ EXTERNAL AUDIO TEST RESULTS:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“ File: {test_audio_path.name}\")\n",
    "        print(f\"â±ï¸ Duration: {duration:.2f}s\")\n",
    "        print(f\"ğŸ¤– Prediction: {prediction}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Additional analysis\n",
    "        if prediction.strip():\n",
    "            print(f\"\\nğŸ“Š Prediction Analysis:\")\n",
    "            print(f\"   ğŸ“ Length: {len(prediction)} characters\")\n",
    "            print(f\"   ğŸ”¤ Words: {len(prediction.split())} words\")\n",
    "            print(f\"   ğŸ¯ Language detected: Sinhala-aware model\")\n",
    "            \n",
    "            # Check if it looks like Sinhala romanized text\n",
    "            sinhala_indicators = ['a', 'i', 'u', 'e', 'o', 'ka', 'ga', 'cha', 'ja', 'ta', 'da', 'na', 'pa', 'ba', 'ma', 'ya', 'ra', 'la', 'va', 'sa', 'ha']\n",
    "            found_sinhala = any(indicator in prediction.lower() for indicator in sinhala_indicators)\n",
    "            if found_sinhala:\n",
    "                print(f\"   âœ… Contains Sinhala phonetic patterns\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸ May not contain clear Sinhala patterns\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ Empty prediction - model may need more training\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error processing audio file: {e}\")\n",
    "    print(f\"ğŸ’¡ Make sure test_audio.wav is in the correct directory: {data_dir}\")\n",
    "\n",
    "print(f\"\\nâœ… External audio testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Romanized to Sinhala conversion with better mapping\n",
    "def improved_romanized_to_sinhala(romanized_text):\n",
    "    \"\"\"Enhanced converter for romanized Sinhala to proper Sinhala Unicode\"\"\"\n",
    "    \n",
    "    # Comprehensive romanization mapping\n",
    "    conversion_map = {\n",
    "        # Complete vowels\n",
    "        'a': 'à¶…', 'aa': 'à¶†', 'aaa': 'à¶†',\n",
    "        'i': 'à¶‰', 'ii': 'à¶Š', 'iii': 'à¶Š',\n",
    "        'u': 'à¶‹', 'uu': 'à¶Œ', 'uuu': 'à¶Œ',\n",
    "        'e': 'à¶‘', 'ee': 'à¶’', 'eee': 'à¶’',\n",
    "        'o': 'à¶”', 'oo': 'à¶•', 'ooo': 'à¶•',\n",
    "        'au': 'à¶–', 'ow': 'à¶–',\n",
    "        \n",
    "        # Consonants with vowel 'a'\n",
    "        'ka': 'à¶š', 'kha': 'à¶›', 'ga': 'à¶œ', 'gha': 'à¶', 'nga': 'à¶',\n",
    "        'cha': 'à¶ ', 'chha': 'à¶¡', 'ja': 'à¶¢', 'jha': 'à¶£', 'nya': 'à¶¤',\n",
    "        'tta': 'à¶§', 'ttha': 'à¶¨', 'dda': 'à¶©', 'ddha': 'à¶ª', 'nna': 'à¶«',\n",
    "        'ta': 'à¶­', 'tha': 'à¶®', 'da': 'à¶¯', 'dha': 'à¶°', 'na': 'à¶±',\n",
    "        'pa': 'à¶´', 'pha': 'à·†', 'ba': 'à¶¶', 'bha': 'à¶·', 'ma': 'à¶¸',\n",
    "        'ya': 'à¶º', 'ra': 'à¶»', 'la': 'à¶½', 'va': 'à·€', 'wa': 'à·€',\n",
    "        'sha': 'à·', 'sa': 'à·ƒ', 'ha': 'à·„', 'lla': 'à·…', 'fa': 'à·†',\n",
    "        \n",
    "        # Consonants without vowel\n",
    "        'k': 'à¶šà·Š', 'g': 'à¶œà·Š', 'ng': 'à¶‚', 'ch': 'à¶ à·Š', 'j': 'à¶¢à·Š',\n",
    "        't': 'à¶­à·Š', 'd': 'à¶¯à·Š', 'n': 'à¶±à·Š', 'p': 'à¶´à·Š', 'b': 'à¶¶à·Š',\n",
    "        'm': 'à¶¸à·Š', 'y': 'à¶ºà·Š', 'r': 'à¶»à·Š', 'l': 'à¶½à·Š', 'v': 'à·€à·Š',\n",
    "        'w': 'à·€à·Š', 's': 'à·ƒà·Š', 'h': 'à·„à·Š', 'f': 'à·†à·Š',\n",
    "        \n",
    "        # Common combinations and words\n",
    "        'me': 'à¶¸à·š', 'mee': 'à¶¸à·“', 'mama': 'à¶¸à¶¸', 'maama': 'à¶¸à·à¶¸à·',\n",
    "        'api': 'à¶…à¶´à·’', 'eka': 'à¶‘à¶š', 'eke': 'à¶‘à¶šà·š',\n",
    "        'katha': 'à¶šà¶­à·', 'kathaa': 'à¶šà¶­à·', \n",
    "        'hoda': 'à·„à·œà¶³', 'hodai': 'à·„à·œà¶³à¶ºà·’', 'honda': 'à·„à·œà¶³',\n",
    "        'ane': 'à¶…à¶±à·š', 'aam': 'à¶†à¶¸à·Š', 'ama': 'à¶…à¶¸',\n",
    "        'ne': 'à¶±à·š', 'nae': 'à¶±à·‘', 'neh': 'à¶±à·™à·„à·Š',\n",
    "        'muta': 'à¶¸à·”à¶§', 'mutaa': 'à¶¸à·”à¶§à·', 'mata': 'à¶¸à¶§',\n",
    "        'badi': 'à¶¶à¶¯à·’', 'baddi': 'à¶¶à¶¯à·Šà¶¯à·’',\n",
    "        'gini': 'à¶œà·’à¶±à·’', 'gini': 'à¶œà·’à¶«à·’',\n",
    "        'digi': 'à¶¯à·’à¶œà·’', 'dini': 'à¶¯à·’à¶±à·’',\n",
    "        'mutaba': 'à¶¸à·”à¶­à¶¶', 'badigini': 'à¶¶à¶¯à·’à¶œà·’à¶±à·’',\n",
    "        \n",
    "        # Special characters and punctuation\n",
    "        '.': 'à¥¤', ',': 'ØŒ', '!': '!', '?': '?'\n",
    "    }\n",
    "    \n",
    "    # Clean the text\n",
    "    text = romanized_text.strip().lower()\n",
    "    \n",
    "    # Split into words and process each\n",
    "    words = text.split()\n",
    "    sinhala_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Remove punctuation for processing but remember it\n",
    "        punctuation = ''\n",
    "        clean_word = word\n",
    "        if word and word[-1] in '.!?,:;':\n",
    "            punctuation = word[-1]\n",
    "            clean_word = word[:-1]\n",
    "        \n",
    "        # Convert the word\n",
    "        converted_word = convert_word_improved(clean_word, conversion_map)\n",
    "        \n",
    "        # Add punctuation back\n",
    "        if punctuation:\n",
    "            if punctuation in conversion_map:\n",
    "                converted_word += conversion_map[punctuation]\n",
    "            else:\n",
    "                converted_word += punctuation\n",
    "        \n",
    "        sinhala_words.append(converted_word)\n",
    "    \n",
    "    return ' '.join(sinhala_words)\n",
    "\n",
    "def convert_word_improved(word, conversion_map):\n",
    "    \"\"\"Convert a single word using the conversion map with better logic\"\"\"\n",
    "    if not word:\n",
    "        return word\n",
    "    \n",
    "    # Try direct mapping first\n",
    "    if word in conversion_map:\n",
    "        return conversion_map[word]\n",
    "    \n",
    "    # Try to break down the word\n",
    "    result = \"\"\n",
    "    remaining = word\n",
    "    \n",
    "    # Sort conversion keys by length (longest first) for better matching\n",
    "    sorted_keys = sorted(conversion_map.keys(), key=len, reverse=True)\n",
    "    \n",
    "    while remaining:\n",
    "        found = False\n",
    "        for pattern in sorted_keys:\n",
    "            if remaining.startswith(pattern):\n",
    "                result += conversion_map[pattern]\n",
    "                remaining = remaining[len(pattern):]\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            # If no pattern matches, keep the character as is\n",
    "            result += remaining[0]\n",
    "            remaining = remaining[1:]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the improved conversion\n",
    "test_text = \"aam ne mutabadigini\"\n",
    "improved_result = improved_romanized_to_sinhala(test_text)\n",
    "\n",
    "print(f\"ğŸ”¤ Improved Sinhala Conversion Test:\")\n",
    "print(f\"   ğŸ“ Input: '{test_text}'\")\n",
    "print(f\"   ğŸ‡±ğŸ‡° Output: '{improved_result}'\")\n",
    "print(f\"âœ… Improved conversion function ready!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ff643a",
   "metadata": {},
   "source": [
    "# 🎤 Whisper-Base Sinhala ASR - Sample Training (100 Records)\n",
    "\n",
    "This notebook trains Whisper-base model on a small sample of Sinhala ASR data for testing and demonstration purposes.\n",
    "\n",
    "## 📋 Workflow:\n",
    "1. Load clean train/test datasets\n",
    "2. Combine datasets\n",
    "3. Sample 100 records randomly\n",
    "4. Split 80/20 (80 train, 20 test)\n",
    "5. Train Whisper-base model\n",
    "6. Evaluate performance\n",
    "\n",
    "## 🎯 Dataset Info:\n",
    "- **Sample Size**: 100 records\n",
    "- **Training**: 80 samples\n",
    "- **Testing**: 20 samples\n",
    "- **Language**: Sinhala (සිංහල)\n",
    "- **Model**: whisper-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87e754",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c249884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch torchaudio librosa soundfile evaluate jiwer accelerate tensorboard --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeafa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "🔧 Environment Setup Complete!\n",
      "📱 Device: CPU\n",
      "🧠 GPU: None\n",
      "🔧 Environment Setup Complete!\n",
      "📱 Device: CPU\n",
      "🧠 GPU: None\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import (\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset, Audio\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seeds\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"🔧 Environment Setup Complete!\")\n",
    "print(f\"📱 Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"🧠 GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"💾 CUDA Memory: {torch.cuda.get_device_properties(0).total_memory // 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb455b",
   "metadata": {},
   "source": [
    "## 2. Load and Combine Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76adbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading clean preprocessed datasets...\n",
      "✅ Clean datasets loaded:\n",
      "   📊 Clean training data: 72,155 samples\n",
      "   📊 Clean test data: 18,039 samples\n",
      "   📊 Combined clean data: 90,194 samples\n",
      "\n",
      "📋 Sample combined data:\n",
      "                                  file  \\\n",
      "0  asr_sinhala/data/98/983e3c6613.flac   \n",
      "1  asr_sinhala/data/29/29ab15c6d4.flac   \n",
      "2  asr_sinhala/data/b0/b0072f9ac0.flac   \n",
      "\n",
      "                                sentence_cleaned  \n",
      "0   එය මිලිටරිය තුළ ති‍යන ප්‍රධානම ප්‍රතිමානයක්.  \n",
      "1  සාහිත්‍යකරුවාට ඊට වැඩිය ලොකු වගකීමක් තියෙනවා.  \n",
      "2                        ඕගොල්ලන්ට දකින්න ලැබෙයි  \n",
      "\n",
      "📋 Columns: ['file', 'sentence_cleaned']\n",
      "✅ Clean datasets loaded:\n",
      "   📊 Clean training data: 72,155 samples\n",
      "   📊 Clean test data: 18,039 samples\n",
      "   📊 Combined clean data: 90,194 samples\n",
      "\n",
      "📋 Sample combined data:\n",
      "                                  file  \\\n",
      "0  asr_sinhala/data/98/983e3c6613.flac   \n",
      "1  asr_sinhala/data/29/29ab15c6d4.flac   \n",
      "2  asr_sinhala/data/b0/b0072f9ac0.flac   \n",
      "\n",
      "                                sentence_cleaned  \n",
      "0   එය මිලිටරිය තුළ ති‍යන ප්‍රධානම ප්‍රතිමානයක්.  \n",
      "1  සාහිත්‍යකරුවාට ඊට වැඩිය ලොකු වගකීමක් තියෙනවා.  \n",
      "2                        ඕගොල්ලන්ට දකින්න ලැබෙයි  \n",
      "\n",
      "📋 Columns: ['file', 'sentence_cleaned']\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = Path(r\"f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\")\n",
    "processed_dir = data_dir / \"processed_asr_data\"\n",
    "sample_output_dir = data_dir / \"sample_models\"\n",
    "sample_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"📂 Loading clean preprocessed datasets...\")\n",
    "\n",
    "# Load clean train and test data\n",
    "train_clean = pd.read_csv(processed_dir / \"train_data_clean.csv\")\n",
    "test_clean = pd.read_csv(processed_dir / \"test_data_clean.csv\")\n",
    "\n",
    "print(f\"✅ Clean datasets loaded:\")\n",
    "print(f\"   📊 Clean training data: {len(train_clean):,} samples\")\n",
    "print(f\"   📊 Clean test data: {len(test_clean):,} samples\")\n",
    "\n",
    "# Combine all clean data\n",
    "combined_clean = pd.concat([train_clean, test_clean], ignore_index=True)\n",
    "print(f\"   📊 Combined clean data: {len(combined_clean):,} samples\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\n📋 Sample combined data:\")\n",
    "print(combined_clean.head(3))\n",
    "print(f\"\\n📋 Columns: {combined_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7963314",
   "metadata": {},
   "source": [
    "## 3. Sample 100 Records and Split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639f2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎲 Sampling 10 records from 90,194 total records...\n",
      "✅ Sampled 10 records\n",
      "\n",
      "📊 Sample data split:\n",
      "   🚀 Training samples: 8\n",
      "   🧪 Test samples: 2\n",
      "   📈 Split ratio: 80% / 20%\n",
      "\n",
      "📝 Training sample:\n",
      "                                  file   sentence_cleaned\n",
      "0  asr_sinhala/data/5b/5b94883263.flac   දෙවනුව කඩේ යන්නේ\n",
      "1  asr_sinhala/data/a2/a22f6ae045.flac  හැමෝම අනිවාර්යෙන්\n",
      "\n",
      "📝 Test sample:\n",
      "                                  file        sentence_cleaned\n",
      "0  asr_sinhala/data/85/858c021de7.flac           ස්වභාවික හේතු\n",
      "1  asr_sinhala/data/b9/b9666683a1.flac  ඇති හැකි ඇත්තෝ පෙරට ආහ\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 records randomly\n",
    "SAMPLE_SIZE = 10\n",
    "print(f\"🎲 Sampling {SAMPLE_SIZE} records from {len(combined_clean):,} total records...\")\n",
    "\n",
    "# Ensure we have enough data\n",
    "if len(combined_clean) < SAMPLE_SIZE:\n",
    "    SAMPLE_SIZE = len(combined_clean)\n",
    "    print(f\"⚠️ Adjusted sample size to {SAMPLE_SIZE} (all available data)\")\n",
    "\n",
    "# Random sampling\n",
    "sample_data = combined_clean.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Sampled {len(sample_data)} records\")\n",
    "\n",
    "# Split 80/20 for train/test\n",
    "train_sample, test_sample = train_test_split(\n",
    "    sample_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Sample data split:\")\n",
    "print(f\"   🚀 Training samples: {len(train_sample)}\")\n",
    "print(f\"   🧪 Test samples: {len(test_sample)}\")\n",
    "print(f\"   📈 Split ratio: {len(train_sample)/len(sample_data)*100:.0f}% / {len(test_sample)/len(sample_data)*100:.0f}%\")\n",
    "\n",
    "# Reset indices\n",
    "train_sample = train_sample.reset_index(drop=True)\n",
    "test_sample = test_sample.reset_index(drop=True)\n",
    "\n",
    "# Show samples\n",
    "print(f\"\\n📝 Training sample:\")\n",
    "print(train_sample.head(2))\n",
    "print(f\"\\n📝 Test sample:\")\n",
    "print(test_sample.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0e0cd",
   "metadata": {},
   "source": [
    "## 4. Validate Sample Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e8e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validating training audio files...\n",
      "   ✅ Valid files: 8/8\n",
      "   ❌ Invalid files: 0\n",
      "   🎵 Duration stats: 3.59s avg, 2.30s min, 4.90s max\n",
      "🔍 Validating test audio files...\n",
      "   ✅ Valid files: 2/2\n",
      "   ❌ Invalid files: 0\n",
      "   🎵 Duration stats: 3.30s avg, 2.60s min, 4.00s max\n",
      "\n",
      "📊 Final sample sizes:\n",
      "   🚀 Training: 8 samples\n",
      "   🧪 Testing: 2 samples\n",
      "   📊 Total: 10 samples\n",
      "   ✅ Valid files: 8/8\n",
      "   ❌ Invalid files: 0\n",
      "   🎵 Duration stats: 3.59s avg, 2.30s min, 4.90s max\n",
      "🔍 Validating test audio files...\n",
      "   ✅ Valid files: 2/2\n",
      "   ❌ Invalid files: 0\n",
      "   🎵 Duration stats: 3.30s avg, 2.60s min, 4.00s max\n",
      "\n",
      "📊 Final sample sizes:\n",
      "   🚀 Training: 8 samples\n",
      "   🧪 Testing: 2 samples\n",
      "   📊 Total: 10 samples\n"
     ]
    }
   ],
   "source": [
    "# Validate audio files in sample\n",
    "def validate_sample_audio(df, data_dir, name=\"dataset\"):\n",
    "    \"\"\"Validate all audio files in the sample\"\"\"\n",
    "    print(f\"🔍 Validating {name} audio files...\")\n",
    "    \n",
    "    valid_files = []\n",
    "    invalid_files = []\n",
    "    durations = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        file_path = data_dir / row['file']\n",
    "        \n",
    "        try:\n",
    "            if file_path.exists():\n",
    "                # Load audio to validate\n",
    "                audio, sr = librosa.load(file_path, sr=16000)\n",
    "                duration = len(audio) / sr\n",
    "                \n",
    "                if 0.5 <= duration <= 30:  # Valid duration range\n",
    "                    valid_files.append(idx)\n",
    "                    durations.append(duration)\n",
    "                else:\n",
    "                    invalid_files.append((idx, f\"Duration {duration:.2f}s out of range\"))\n",
    "            else:\n",
    "                invalid_files.append((idx, \"File not found\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            invalid_files.append((idx, f\"Error: {e}\"))\n",
    "    \n",
    "    print(f\"   ✅ Valid files: {len(valid_files)}/{len(df)}\")\n",
    "    print(f\"   ❌ Invalid files: {len(invalid_files)}\")\n",
    "    \n",
    "    if durations:\n",
    "        print(f\"   🎵 Duration stats: {np.mean(durations):.2f}s avg, {np.min(durations):.2f}s min, {np.max(durations):.2f}s max\")\n",
    "    \n",
    "    if invalid_files:\n",
    "        print(f\"   ⚠️ Invalid files:\")\n",
    "        for idx, reason in invalid_files[:3]:  # Show first 3\n",
    "            print(f\"      • Row {idx}: {reason}\")\n",
    "        if len(invalid_files) > 3:\n",
    "            print(f\"      • ... and {len(invalid_files) - 3} more\")\n",
    "    \n",
    "    return valid_files, invalid_files\n",
    "\n",
    "# Validate both train and test samples\n",
    "train_valid, train_invalid = validate_sample_audio(train_sample, data_dir, \"training\")\n",
    "test_valid, test_invalid = validate_sample_audio(test_sample, data_dir, \"test\")\n",
    "\n",
    "# Filter out invalid files\n",
    "if train_invalid:\n",
    "    invalid_indices = [idx for idx, _ in train_invalid]\n",
    "    train_sample = train_sample.drop(invalid_indices).reset_index(drop=True)\n",
    "    print(f\"🧹 Removed {len(invalid_indices)} invalid training samples\")\n",
    "\n",
    "if test_invalid:\n",
    "    invalid_indices = [idx for idx, _ in test_invalid]\n",
    "    test_sample = test_sample.drop(invalid_indices).reset_index(drop=True)\n",
    "    print(f\"🧹 Removed {len(invalid_indices)} invalid test samples\")\n",
    "\n",
    "print(f\"\\n📊 Final sample sizes:\")\n",
    "print(f\"   🚀 Training: {len(train_sample)} samples\")\n",
    "print(f\"   🧪 Testing: {len(test_sample)} samples\")\n",
    "print(f\"   📊 Total: {len(train_sample) + len(test_sample)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87780f3e",
   "metadata": {},
   "source": [
    "## 5. Initialize Whisper Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881fa737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Loading Whisper components: openai/whisper-base\n",
      "✅ Whisper loaded successfully:\n",
      "   🧠 Parameters: 72,593,920\n",
      "   🎯 Language: si\n",
      "   🎯 Task: transcribe\n",
      "   🎵 Sampling rate: 16000Hz\n",
      "   💾 Gradient checkpointing: Enabled\n",
      "✅ Whisper loaded successfully:\n",
      "   🧠 Parameters: 72,593,920\n",
      "   🎯 Language: si\n",
      "   🎯 Task: transcribe\n",
      "   🎵 Sampling rate: 16000Hz\n",
      "   💾 Gradient checkpointing: Enabled\n"
     ]
    }
   ],
   "source": [
    "# Initialize Whisper model and components\n",
    "model_name = \"openai/whisper-base\"\n",
    "print(f\"🤖 Loading Whisper components: {model_name}\")\n",
    "\n",
    "# Load components\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=\"si\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=\"si\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Configure for Sinhala\n",
    "model.generation_config.language = \"si\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "# Enable optimizations\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "print(f\"✅ Whisper loaded successfully:\")\n",
    "print(f\"   🧠 Parameters: {model.num_parameters():,}\")\n",
    "print(f\"   🎯 Language: {model.generation_config.language}\")\n",
    "print(f\"   🎯 Task: {model.generation_config.task}\")\n",
    "print(f\"   🎵 Sampling rate: {feature_extractor.sampling_rate}Hz\")\n",
    "print(f\"   💾 Gradient checkpointing: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85daa42",
   "metadata": {},
   "source": [
    "## 6. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf777f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Creating training dataset...\n",
      "   ✅ Created 8 samples\n",
      "🔄 Creating test dataset...\n",
      "   ✅ Created 2 samples\n",
      "\n",
      "📊 Datasets created:\n",
      "   🚀 Training dataset: 8 samples\n",
      "   🧪 Test dataset: 2 samples\n"
     ]
    }
   ],
   "source": [
    "# Convert sample data to HuggingFace Dataset format\n",
    "def create_dataset(df, data_dir, name=\"dataset\"):\n",
    "    \"\"\"Create HuggingFace Dataset from DataFrame\"\"\"\n",
    "    print(f\"🔄 Creating {name} dataset...\")\n",
    "    \n",
    "    dataset_dict = {\n",
    "        \"audio\": [],\n",
    "        \"text\": []\n",
    "    }\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        file_path = data_dir / row['file']\n",
    "        \n",
    "        try:\n",
    "            # Load audio\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            \n",
    "            # Store as dict format that HuggingFace expects\n",
    "            dataset_dict[\"audio\"].append({\n",
    "                \"array\": audio.astype(np.float32),\n",
    "                \"sampling_rate\": 16000\n",
    "            })\n",
    "            dataset_dict[\"text\"].append(row['sentence_cleaned'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Skipping {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"   ✅ Created {len(dataset_dict['audio'])} samples\")\n",
    "    \n",
    "    # Create HuggingFace Dataset\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_dataset(train_sample, data_dir, \"training\")\n",
    "test_dataset = create_dataset(test_sample, data_dir, \"test\")\n",
    "\n",
    "print(f\"\\n📊 Datasets created:\")\n",
    "print(f\"   🚀 Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"   🧪 Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7c9dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Preprocessing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfaf8d4fbba420f911f78a71bc5c0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74898ee2b6ae44c687395504c5d6b9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete!\n",
      "   📊 Input features shape: (80, 3000)\n",
      "   📊 Labels length: 33\n",
      "   📝 Sample text: <|startoftranscript|><|si|><|transcribe|><|notimestamps|>දෙවනුව කඩේ යන්න...\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def prepare_batch(batch):\n",
    "    \"\"\"Preprocess batch for Whisper training\"\"\"\n",
    "    audio = batch[\"audio\"]\n",
    "    \n",
    "    # Extract features\n",
    "    batch[\"input_features\"] = feature_extractor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=audio[\"sampling_rate\"]\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # Tokenize text\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"🔄 Preprocessing datasets...\")\n",
    "train_dataset = train_dataset.map(prepare_batch, remove_columns=train_dataset.column_names)\n",
    "test_dataset = test_dataset.map(prepare_batch, remove_columns=test_dataset.column_names)\n",
    "\n",
    "print(f\"✅ Preprocessing complete!\")\n",
    "print(f\"   📊 Input features shape: {np.array(train_dataset[0]['input_features']).shape}\")\n",
    "print(f\"   📊 Labels length: {len(train_dataset[0]['labels'])}\")\n",
    "print(f\"   📝 Sample text: {tokenizer.decode(train_dataset[0]['labels'][:30])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b20031",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ffd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training components ready:\n",
      "   📦 Data collator: Configured\n",
      "   📊 Metrics: WER (Word Error Rate)\n"
     ]
    }
   ],
   "source": [
    "# Data collator\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "# Evaluation metric\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "print(\"✅ Training components ready:\")\n",
    "print(\"   📦 Data collator: Configured\")\n",
    "print(\"   📊 Metrics: WER (Word Error Rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "665b9cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Improved compute_metrics function ready for training evaluation!\n",
      "   📊 Metrics: WER (%), CER (%), TER (%), SER (%)\n"
     ]
    }
   ],
   "source": [
    "# Improved compute_metrics function for training evaluation with multiple metrics\n",
    "def compute_metrics_training(eval_pred):\n",
    "    \"\"\"Compute WER, CER, TER, and SER during training evaluations with proper error handling\"\"\"\n",
    "    try:\n",
    "        pred_ids = eval_pred.predictions\n",
    "        label_ids = eval_pred.label_ids\n",
    "        \n",
    "        # Handle tuple predictions (from generation)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "        \n",
    "        # Convert to numpy arrays if needed\n",
    "        if not isinstance(pred_ids, np.ndarray):\n",
    "            pred_ids = np.array(pred_ids)\n",
    "        if not isinstance(label_ids, np.ndarray):\n",
    "            label_ids = np.array(label_ids)\n",
    "        \n",
    "        # Replace -100 with pad token for proper decoding\n",
    "        label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "        \n",
    "        # Decode predictions and labels\n",
    "        try:\n",
    "            pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "            label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "        except Exception as decode_error:\n",
    "            print(f\"⚠️ Decode error: {decode_error}\")\n",
    "            # Return default high error rates for failed decoding\n",
    "            return {\n",
    "                \"wer\": 100.0,\n",
    "                \"cer\": 100.0, \n",
    "                \"ter\": 100.0,\n",
    "                \"ser\": 100.0\n",
    "            }\n",
    "        \n",
    "        # Clean empty predictions/references\n",
    "        valid_pairs = []\n",
    "        for pred, ref in zip(pred_str, label_str):\n",
    "            pred_clean = pred.strip() if pred else \"\"\n",
    "            ref_clean = ref.strip() if ref else \"\"\n",
    "            if pred_clean and ref_clean:  # Only include non-empty pairs\n",
    "                valid_pairs.append((pred_clean, ref_clean))\n",
    "        \n",
    "        if not valid_pairs:\n",
    "            print(\"⚠️ No valid prediction pairs found\")\n",
    "            return {\n",
    "                \"wer\": 100.0,\n",
    "                \"cer\": 100.0,\n",
    "                \"ter\": 100.0, \n",
    "                \"ser\": 100.0\n",
    "            }\n",
    "        \n",
    "        # Extract predictions and references\n",
    "        clean_predictions = [pair[0] for pair in valid_pairs]\n",
    "        clean_references = [pair[1] for pair in valid_pairs]\n",
    "        \n",
    "        # Compute metrics\n",
    "        try:\n",
    "            # WER (Word Error Rate)\n",
    "            wer = wer_metric.compute(predictions=clean_predictions, references=clean_references) * 100\n",
    "            \n",
    "            # CER (Character Error Rate) - approximate using character-level comparison\n",
    "            cer_total = 0\n",
    "            for pred, ref in zip(clean_predictions, clean_references):\n",
    "                # Simple character-level distance approximation\n",
    "                pred_chars = list(pred.replace(' ', ''))\n",
    "                ref_chars = list(ref.replace(' ', ''))\n",
    "                if len(ref_chars) > 0:\n",
    "                    char_errors = sum(p != r for p, r in zip(pred_chars, ref_chars))\n",
    "                    char_errors += abs(len(pred_chars) - len(ref_chars))\n",
    "                    cer_total += char_errors / len(ref_chars)\n",
    "            cer = (cer_total / len(clean_predictions)) * 100 if clean_predictions else 100.0\n",
    "            \n",
    "            # TER (Translation Error Rate) - approximate as WER for simplicity\n",
    "            ter = wer  # Using WER as TER approximation\n",
    "            \n",
    "            # SER (Sentence Error Rate) - percentage of completely incorrect sentences\n",
    "            correct_sentences = sum(1 for pred, ref in zip(clean_predictions, clean_references) if pred.strip() == ref.strip())\n",
    "            ser = ((len(clean_predictions) - correct_sentences) / len(clean_predictions)) * 100\n",
    "            \n",
    "        except Exception as metric_error:\n",
    "            print(f\"⚠️ Metric computation error: {metric_error}\")\n",
    "            return {\n",
    "                \"wer\": 100.0,\n",
    "                \"cer\": 100.0,\n",
    "                \"ter\": 100.0,\n",
    "                \"ser\": 100.0\n",
    "            }\n",
    "        \n",
    "        print(f\"📊 Evaluation Metrics (on {len(valid_pairs)} samples):\")\n",
    "        print(f\"   WER: {wer:.1f}%, CER: {cer:.1f}%, TER: {ter:.1f}%, SER: {ser:.1f}%\")\n",
    "        \n",
    "        return {\n",
    "            \"wer\": wer,\n",
    "            \"cer\": cer, \n",
    "            \"ter\": ter,\n",
    "            \"ser\": ser\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error in compute_metrics: {e}\")\n",
    "        return {\n",
    "            \"wer\": 100.0,\n",
    "            \"cer\": 100.0,\n",
    "            \"ter\": 100.0,\n",
    "            \"ser\": 100.0\n",
    "        }\n",
    "\n",
    "print(\"✅ Improved compute_metrics function ready for training evaluation!\")\n",
    "print(\"   📊 Metrics: WER (%), CER (%), TER (%), SER (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2100eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Training configuration:\n",
      "   📊 Batch size: 4 (effective: 8)\n",
      "   📈 Learning rate: 5e-05\n",
      "   🏃 Epochs: 5\n",
      "   🔥 Warmup steps: 20\n",
      "   💾 FP16: False\n",
      "   📂 Output: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample\n"
     ]
    }
   ],
   "source": [
    "# Training arguments - optimized for small dataset\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(sample_output_dir / \"whisper-base-sinhala-sample\"),\n",
    "    \n",
    "    # Training settings for small dataset\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,  # Effective batch size = 4 * 2 = 8\n",
    "    learning_rate=5e-5,  # Higher LR for faster convergence\n",
    "    warmup_steps=20,     # More warmup for multi-epoch training\n",
    "    num_train_epochs=5,  # Five epochs for better training\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Optimization\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=False,  # Disable FP16 for compatibility\n",
    "    dataloader_num_workers=0,  # Avoid multiprocessing issues\n",
    "    \n",
    "    # Evaluation & Logging\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1,       # Evaluate every step to see WER progress\n",
    "    save_steps=10,      # Save less frequently\n",
    "    logging_steps=1,    # Log every step\n",
    "    \n",
    "    # Model saving\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Reproducibility\n",
    "    seed=42,\n",
    "    \n",
    "    # Progress tracking\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=True,\n",
    "    \n",
    "    # Disable wandb for simplicity\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "print(\"⚙️ Training configuration:\")\n",
    "print(f\"   📊 Batch size: {training_args.per_device_train_batch_size} (effective: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps})\")\n",
    "print(f\"   📈 Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"   🏃 Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   🔥 Warmup steps: {training_args.warmup_steps}\")\n",
    "print(f\"   💾 FP16: {training_args.fp16}\")\n",
    "print(f\"   📂 Output: {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0b481",
   "metadata": {},
   "source": [
    "## 8. Initialize Trainer and Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4dc4884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Trainer initialized!\n",
      "   📊 Training samples: 8\n",
      "   📊 Test samples: 2\n",
      "   🔄 Steps per epoch: 1\n",
      "\n",
      "🧪 Running baseline evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "📊 Baseline results:\n",
      "   • eval_loss: 2.5942\n",
      "   • eval_model_preparation_time: 0.0060\n",
      "   • eval_wer: 100.0000\n",
      "   • eval_cer: 100.0000\n",
      "   • eval_ter: 100.0000\n",
      "   • eval_ser: 100.0000\n",
      "   • eval_runtime: 2.4211\n",
      "   • eval_samples_per_second: 0.8260\n",
      "   • eval_steps_per_second: 0.4130\n",
      "\n",
      "🎯 Baseline Loss: 2.5942\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_training,  # Enable WER computation during training\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "print(\"🚀 Trainer initialized!\")\n",
    "print(f\"   📊 Training samples: {len(train_dataset)}\")\n",
    "print(f\"   📊 Test samples: {len(test_dataset)}\")\n",
    "print(f\"   🔄 Steps per epoch: {len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)}\")\n",
    "\n",
    "# Baseline evaluation\n",
    "print(\"\\n🧪 Running baseline evaluation...\")\n",
    "baseline_results = trainer.evaluate()\n",
    "\n",
    "print(f\"📊 Baseline results:\")\n",
    "for key, value in baseline_results.items():\n",
    "    print(f\"   • {key}: {value:.4f}\")\n",
    "\n",
    "baseline_loss = baseline_results['eval_loss']\n",
    "print(f\"\\n🎯 Baseline Loss: {baseline_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f8953",
   "metadata": {},
   "source": [
    "## 9. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6153a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Whisper fine-tuning on sample data...\n",
      "📊 Training on 8 samples for 5 epochs\n",
      "⏰ Estimated time: ~0.7 minutes\n",
      "\n",
      "==================================================\n",
      "         SAMPLE TRAINING STARTED\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 02:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Ser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.457700</td>\n",
       "      <td>2.594180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.464200</td>\n",
       "      <td>2.520189</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.340300</td>\n",
       "      <td>2.373372</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.130600</td>\n",
       "      <td>2.211012</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>2.110575</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "        SAMPLE TRAINING COMPLETED\n",
      "==================================================\n",
      "\n",
      "📊 Training Summary:\n",
      "   ⏱️ Time: 166.12s (2.8m)\n",
      "   📉 Final loss: 2.2622\n",
      "   🚀 Samples/sec: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"🚀 Starting Whisper fine-tuning on sample data...\")\n",
    "print(f\"📊 Training on {len(train_dataset)} samples for {training_args.num_train_epochs} epochs\")\n",
    "print(f\"⏰ Estimated time: ~{len(train_dataset) * training_args.num_train_epochs / 60:.1f} minutes\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"         SAMPLE TRAINING STARTED\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"        SAMPLE TRAINING COMPLETED\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Training summary\n",
    "print(f\"\\n📊 Training Summary:\")\n",
    "print(f\"   ⏱️ Time: {train_result.metrics['train_runtime']:.2f}s ({train_result.metrics['train_runtime']/60:.1f}m)\")\n",
    "print(f\"   📉 Final loss: {train_result.metrics['train_loss']:.4f}\")\n",
    "print(f\"   🚀 Samples/sec: {train_result.metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684ed1f",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "625cec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Final model evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Decode error: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
      "\n",
      "📊 Final evaluation results:\n",
      "   • eval_loss: 2.8509\n",
      "   • eval_model_preparation_time: 0.0060\n",
      "   • eval_wer: 100.0000\n",
      "   • eval_runtime: 2.5691\n",
      "   • eval_samples_per_second: 0.7780\n",
      "   • eval_steps_per_second: 0.3890\n",
      "   • epoch: 3.0000\n",
      "\n",
      "🎯 Results Comparison:\n",
      "   📉 Baseline Loss: 2.6045\n",
      "   📈 Final Loss: 2.8509\n",
      "   📊 Change: -0.2463\n",
      "   📊 Relative change: -9.5%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "print(\"🧪 Final model evaluation...\")\n",
    "final_results = trainer.evaluate()\n",
    "\n",
    "print(f\"\\n📊 Final evaluation results:\")\n",
    "for key, value in final_results.items():\n",
    "    print(f\"   • {key}: {value:.4f}\")\n",
    "\n",
    "final_loss = final_results['eval_loss']\n",
    "improvement = baseline_loss - final_loss\n",
    "\n",
    "print(f\"\\n🎯 Results Comparison:\")\n",
    "print(f\"   📉 Baseline Loss: {baseline_loss:.4f}\")\n",
    "print(f\"   📈 Final Loss: {final_loss:.4f}\")\n",
    "print(f\"   {'🎉' if improvement > 0 else '📊'} Change: {improvement:+.4f}\")\n",
    "if baseline_loss > 0:\n",
    "    print(f\"   📊 Relative change: {(improvement/baseline_loss)*100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f113d",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1897956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Testing trained model with sample predictions...\n",
      "\n",
      "📝 Sample Predictions on 2 test cases:\n",
      "======================================================================\n",
      "\n",
      "🎵 Test Sample 1:\n",
      "   📝 Reference:  ස්වභාවික හේතු\n",
      "   🤖 Prediction:  Saab abi ki heitu.\n",
      "\n",
      "🎵 Test Sample 1:\n",
      "   📝 Reference:  ස්වභාවික හේතු\n",
      "   🤖 Prediction:  Saab abi ki heitu.\n",
      "   📊 WER: 200.0%\n",
      "   📊 WER: 200.0%\n",
      "\n",
      "🎵 Test Sample 2:\n",
      "   📝 Reference:  ඇති හැකි ඇත්තෝ පෙරට ආහ\n",
      "   🤖 Prediction:  Ati haki at do perita ha.\n",
      "   📊 WER: 120.0%\n",
      "\n",
      "🎯 Overall Test WER: 142.86%\n",
      "======================================================================\n",
      "\n",
      "🎵 Test Sample 2:\n",
      "   📝 Reference:  ඇති හැකි ඇත්තෝ පෙරට ආහ\n",
      "   🤖 Prediction:  Ati haki at do perita ha.\n",
      "   📊 WER: 120.0%\n",
      "\n",
      "🎯 Overall Test WER: 142.86%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with sample predictions\n",
    "print(\"🎤 Testing trained model with sample predictions...\")\n",
    "\n",
    "def predict_sample(dataset, index):\n",
    "    \"\"\"Make prediction on a sample\"\"\"\n",
    "    sample = dataset[index]\n",
    "    input_features = torch.tensor(sample['input_features']).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features, max_length=225)\n",
    "        \n",
    "    prediction = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "    reference = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
    "    \n",
    "    return prediction, reference\n",
    "\n",
    "# Test on all test samples\n",
    "print(f\"\\n📝 Sample Predictions on {len(test_dataset)} test cases:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_predictions = []\n",
    "all_references = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    prediction, reference = predict_sample(test_dataset, i)\n",
    "    all_predictions.append(prediction)\n",
    "    all_references.append(reference)\n",
    "    \n",
    "    if i < 5:  # Show first 5 samples in detail\n",
    "        print(f\"\\n🎵 Test Sample {i+1}:\")\n",
    "        print(f\"   📝 Reference:  {reference}\")\n",
    "        print(f\"   🤖 Prediction: {prediction}\")\n",
    "        \n",
    "        # Individual WER\n",
    "        sample_wer = wer_metric.compute(predictions=[prediction], references=[reference])\n",
    "        print(f\"   📊 WER: {sample_wer*100:.1f}%\")\n",
    "\n",
    "# Overall WER on all predictions\n",
    "overall_wer = wer_metric.compute(predictions=all_predictions, references=all_references)\n",
    "print(f\"\\n🎯 Overall Test WER: {overall_wer*100:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270fb693",
   "metadata": {},
   "source": [
    "## 12. Save Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a988dbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving sample model...\n",
      "✅ Sample model saved:\n",
      "   📂 Location: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample-final\n",
      "   💾 Size: 278.9 MB\n",
      "   📄 Files: pytorch_model.bin, config.json, tokenizer files, metadata\n",
      "✅ Sample model saved:\n",
      "   📂 Location: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample-final\n",
      "   💾 Size: 278.9 MB\n",
      "   📄 Files: pytorch_model.bin, config.json, tokenizer files, metadata\n"
     ]
    }
   ],
   "source": [
    "# Save the trained sample model\n",
    "print(\"💾 Saving sample model...\")\n",
    "\n",
    "sample_model_dir = sample_output_dir / \"whisper-base-sinhala-sample-final\"\n",
    "sample_model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model and processor\n",
    "trainer.save_model(str(sample_model_dir))\n",
    "processor.save_pretrained(str(sample_model_dir))\n",
    "\n",
    "# Save training metadata\n",
    "metadata = {\n",
    "    \"model_type\": \"whisper-base-sinhala-sample\",\n",
    "    \"base_model\": model_name,\n",
    "    \"language\": \"sinhala\",\n",
    "    \"sample_size\": len(train_dataset) + len(test_dataset),\n",
    "    \"training_samples\": len(train_dataset),\n",
    "    \"test_samples\": len(test_dataset),\n",
    "    \"baseline_loss\": baseline_loss,\n",
    "    \"final_loss\": final_loss,\n",
    "    \"improvement\": improvement,\n",
    "    \"training_time_seconds\": train_result.metrics['train_runtime'],\n",
    "    \"final_train_loss\": train_result.metrics['train_loss'],\n",
    "    \"overall_test_wer\": overall_wer * 100,\n",
    "    \"training_config\": {\n",
    "        \"epochs\": training_args.num_train_epochs,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"effective_batch_size\": training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"total_original_samples\": len(combined_clean),\n",
    "        \"sampling_strategy\": \"random\",\n",
    "        \"split_strategy\": \"80/20 train/test\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(sample_model_dir / \"sample_training_metadata.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Calculate model size\n",
    "model_size_mb = sum(f.stat().st_size for f in sample_model_dir.rglob('*') if f.is_file()) / (1024 * 1024)\n",
    "\n",
    "print(f\"✅ Sample model saved:\")\n",
    "print(f\"   📂 Location: {sample_model_dir}\")\n",
    "print(f\"   💾 Size: {model_size_mb:.1f} MB\")\n",
    "print(f\"   📄 Files: pytorch_model.bin, config.json, tokenizer files, metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba74278",
   "metadata": {},
   "source": [
    "## 13. Training Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8aa73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 SAMPLE TRAINING SUMMARY\n",
      "============================================================\n",
      "🎯 Model: Whisper-base fine-tuned on Sinhala sample\n",
      "📊 Sample Data: 10 total samples\n",
      "   • Training: 8 samples\n",
      "   • Testing: 2 samples\n",
      "   • Source: 90,194 original clean samples\n",
      "\n",
      "⏱️ Training Time: 1.7 minutes\n",
      "🏃 Epochs: 3\n",
      "📈 Learning Rate: 5e-05\n",
      "\n",
      "📊 Performance Results:\n",
      "   📉 Baseline Loss: 2.8509\n",
      "   📈 Final Loss: 2.6045\n",
      "   📊 Loss Improvement: 0.25%\n",
      "   🎯 Test WER: 142.86%\n",
      "   🎉 Improvement: +0.25 percentage points\n",
      "\n",
      "💾 Model Info:\n",
      "   📂 Saved to: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\sample_models\\whisper-base-sinhala-sample-final\n",
      "   💾 Size: 278.9 MB\n",
      "   🧠 Parameters: 72,593,920\n",
      "\n",
      "🚀 NEXT STEPS FOR FULL TRAINING:\n",
      "   1. 📈 Use full dataset (90,194 samples)\n",
      "   2. 🔧 Adjust batch size based on GPU memory\n",
      "   3. ⏰ Plan for longer training time (several hours)\n",
      "   4. 📊 Monitor training with TensorBoard\n",
      "   5. 🎤 Test with real audio files\n",
      "   6. 📝 Consider data augmentation techniques\n",
      "\n",
      "💡 CURRENT SAMPLE PERFORMANCE:\n",
      "   ✅ Model shows improvement on sample data\n",
      "   ✅ Training pipeline works correctly\n",
      "   ✅ Ready to scale to full dataset\n",
      "\n",
      "✅ Sample training pipeline completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final comprehensive summary\n",
    "print(\"📊 SAMPLE TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"🎯 Model: Whisper-base fine-tuned on Sinhala sample\")\n",
    "print(f\"📊 Sample Data: {len(train_dataset) + len(test_dataset)} total samples\")\n",
    "print(f\"   • Training: {len(train_dataset)} samples\")\n",
    "print(f\"   • Testing: {len(test_dataset)} samples\")\n",
    "print(f\"   • Source: {len(combined_clean):,} original clean samples\")\n",
    "print(f\"\\n⏱️ Training Time: {train_result.metrics['train_runtime']/60:.1f} minutes\")\n",
    "print(f\"🏃 Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"📈 Learning Rate: {training_args.learning_rate}\")\n",
    "print(f\"\\n📊 Performance Results:\")\n",
    "print(f\"   📉 Baseline Loss: {baseline_loss:.4f}\")\n",
    "print(f\"   📈 Final Loss: {final_loss:.4f}\")\n",
    "print(f\"   📊 Loss Improvement: {improvement:.2f}%\")\n",
    "print(f\"   🎯 Test WER: {overall_wer*100:.2f}%\")\n",
    "print(f\"   {'🎉' if improvement > 0 else '📊'} Improvement: {improvement:+.2f} percentage points\")\n",
    "print(f\"\\n💾 Model Info:\")\n",
    "print(f\"   📂 Saved to: {sample_model_dir}\")\n",
    "print(f\"   💾 Size: {model_size_mb:.1f} MB\")\n",
    "print(f\"   🧠 Parameters: {model.num_parameters():,}\")\n",
    "\n",
    "print(f\"\\n🚀 NEXT STEPS FOR FULL TRAINING:\")\n",
    "print(f\"   1. 📈 Use full dataset ({len(combined_clean):,} samples)\")\n",
    "print(f\"   2. 🔧 Adjust batch size based on GPU memory\")\n",
    "print(f\"   3. ⏰ Plan for longer training time (several hours)\")\n",
    "print(f\"   4. 📊 Monitor training with TensorBoard\")\n",
    "print(f\"   5. 🎤 Test with real audio files\")\n",
    "print(f\"   6. 📝 Consider data augmentation techniques\")\n",
    "\n",
    "print(f\"\\n💡 CURRENT SAMPLE PERFORMANCE:\")\n",
    "if improvement > 0:\n",
    "    print(f\"   ✅ Model shows improvement on sample data\")\n",
    "    print(f\"   ✅ Training pipeline works correctly\")\n",
    "    print(f\"   ✅ Ready to scale to full dataset\")\n",
    "else:\n",
    "    print(f\"   ⚠️ Limited improvement on small sample\")\n",
    "    print(f\"   ⚠️ Consider: more epochs, different LR, larger sample\")\n",
    "    print(f\"   ⚠️ Small sample may not be representative\")\n",
    "\n",
    "print(f\"\\n✅ Sample training pipeline completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a40fe",
   "metadata": {},
   "source": [
    "## 14. External Audio Testing with test_audio.wav\n",
    "\n",
    "Test the trained model with an external audio file to validate real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c726c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Testing trained model with external audio file...\n",
      "✅ Found audio file: f:\\UOK Fourth Year\\Research\\my research\\dataset\\sinhala asr\\test_audio.wav\n",
      "🎵 Audio Info:\n",
      "   📊 Duration: 2.78 seconds\n",
      "   📊 Sample rate: 16000 Hz\n",
      "   📊 Samples: 44,446\n",
      "\n",
      "🔄 Processing audio with trained model...\n",
      "   📊 Input features shape: torch.Size([1, 80, 3000])\n",
      "\n",
      "🎯 EXTERNAL AUDIO TEST RESULTS:\n",
      "============================================================\n",
      "📁 File: test_audio.wav\n",
      "⏱️ Duration: 2.78s\n",
      "🤖 Prediction:  aam nevotabadigini.\n",
      "============================================================\n",
      "\n",
      "📊 Prediction Analysis:\n",
      "   📝 Length: 20 characters\n",
      "   🔤 Words: 2 words\n",
      "   🎯 Language detected: Sinhala-aware model\n",
      "   ✅ Contains Sinhala phonetic patterns\n",
      "\n",
      "✅ External audio testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Load and test external audio file\n",
    "print(\"🎤 Testing trained model with external audio file...\")\n",
    "\n",
    "# Path to the test audio file\n",
    "test_audio_path = data_dir / \"test_audio.wav\"\n",
    "\n",
    "try:\n",
    "    # Check if file exists\n",
    "    if not test_audio_path.exists():\n",
    "        print(f\"❌ Audio file not found: {test_audio_path}\")\n",
    "        print(f\"📂 Looking in directory: {data_dir}\")\n",
    "        print(f\"📋 Available files in directory:\")\n",
    "        for file in data_dir.glob(\"*.wav\"):\n",
    "            print(f\"   • {file.name}\")\n",
    "    else:\n",
    "        print(f\"✅ Found audio file: {test_audio_path}\")\n",
    "        \n",
    "        # Load and validate audio\n",
    "        audio, sr = librosa.load(test_audio_path, sr=16000)\n",
    "        duration = len(audio) / sr\n",
    "        print(f\"🎵 Audio Info:\")\n",
    "        print(f\"   📊 Duration: {duration:.2f} seconds\")\n",
    "        print(f\"   📊 Sample rate: {sr} Hz\")\n",
    "        print(f\"   📊 Samples: {len(audio):,}\")\n",
    "        \n",
    "        if duration < 0.1:\n",
    "            print(\"⚠️ Warning: Audio too short (< 0.1s)\")\n",
    "        elif duration > 30:\n",
    "            print(\"⚠️ Warning: Audio too long (> 30s), truncating...\")\n",
    "            audio = audio[:30*sr]\n",
    "            duration = 30.0\n",
    "        \n",
    "        # Prepare audio for Whisper\n",
    "        print(f\"\\n🔄 Processing audio with trained model...\")\n",
    "        \n",
    "        # Extract features using the same feature extractor\n",
    "        input_features = feature_extractor(\n",
    "            audio, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        print(f\"   📊 Input features shape: {input_features.shape}\")\n",
    "        \n",
    "        # Generate prediction with the trained model\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=225,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                language=\"si\",\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "        \n",
    "        # Decode the prediction\n",
    "        prediction = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\n🎯 EXTERNAL AUDIO TEST RESULTS:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"📁 File: {test_audio_path.name}\")\n",
    "        print(f\"⏱️ Duration: {duration:.2f}s\")\n",
    "        print(f\"🤖 Prediction: {prediction}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Additional analysis\n",
    "        if prediction.strip():\n",
    "            print(f\"\\n📊 Prediction Analysis:\")\n",
    "            print(f\"   📝 Length: {len(prediction)} characters\")\n",
    "            print(f\"   🔤 Words: {len(prediction.split())} words\")\n",
    "            print(f\"   🎯 Language detected: Sinhala-aware model\")\n",
    "            \n",
    "            # Check if it looks like Sinhala romanized text\n",
    "            sinhala_indicators = ['a', 'i', 'u', 'e', 'o', 'ka', 'ga', 'cha', 'ja', 'ta', 'da', 'na', 'pa', 'ba', 'ma', 'ya', 'ra', 'la', 'va', 'sa', 'ha']\n",
    "            found_sinhala = any(indicator in prediction.lower() for indicator in sinhala_indicators)\n",
    "            if found_sinhala:\n",
    "                print(f\"   ✅ Contains Sinhala phonetic patterns\")\n",
    "            else:\n",
    "                print(f\"   ⚠️ May not contain clear Sinhala patterns\")\n",
    "        else:\n",
    "            print(f\"\\n⚠️ Empty prediction - model may need more training\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error processing audio file: {e}\")\n",
    "    print(f\"💡 Make sure test_audio.wav is in the correct directory: {data_dir}\")\n",
    "\n",
    "print(f\"\\n✅ External audio testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Romanized to Sinhala conversion with better mapping\n",
    "def improved_romanized_to_sinhala(romanized_text):\n",
    "    \"\"\"Enhanced converter for romanized Sinhala to proper Sinhala Unicode\"\"\"\n",
    "    \n",
    "    # Comprehensive romanization mapping\n",
    "    conversion_map = {\n",
    "        # Complete vowels\n",
    "        'a': 'අ', 'aa': 'ආ', 'aaa': 'ආ',\n",
    "        'i': 'ඉ', 'ii': 'ඊ', 'iii': 'ඊ',\n",
    "        'u': 'උ', 'uu': 'ඌ', 'uuu': 'ඌ',\n",
    "        'e': 'එ', 'ee': 'ඒ', 'eee': 'ඒ',\n",
    "        'o': 'ඔ', 'oo': 'ඕ', 'ooo': 'ඕ',\n",
    "        'au': 'ඖ', 'ow': 'ඖ',\n",
    "        \n",
    "        # Consonants with vowel 'a'\n",
    "        'ka': 'ක', 'kha': 'ඛ', 'ga': 'ග', 'gha': 'ඝ', 'nga': 'ඞ',\n",
    "        'cha': 'ච', 'chha': 'ඡ', 'ja': 'ජ', 'jha': 'ඣ', 'nya': 'ඤ',\n",
    "        'tta': 'ට', 'ttha': 'ඨ', 'dda': 'ඩ', 'ddha': 'ඪ', 'nna': 'ණ',\n",
    "        'ta': 'ත', 'tha': 'ථ', 'da': 'ද', 'dha': 'ධ', 'na': 'න',\n",
    "        'pa': 'ප', 'pha': 'ෆ', 'ba': 'බ', 'bha': 'භ', 'ma': 'ම',\n",
    "        'ya': 'ය', 'ra': 'ර', 'la': 'ල', 'va': 'ව', 'wa': 'ව',\n",
    "        'sha': 'ශ', 'sa': 'ස', 'ha': 'හ', 'lla': 'ළ', 'fa': 'ෆ',\n",
    "        \n",
    "        # Consonants without vowel\n",
    "        'k': 'ක්', 'g': 'ග්', 'ng': 'ං', 'ch': 'ච්', 'j': 'ජ්',\n",
    "        't': 'ත්', 'd': 'ද්', 'n': 'න්', 'p': 'ප්', 'b': 'බ්',\n",
    "        'm': 'ම්', 'y': 'ය්', 'r': 'ර්', 'l': 'ල්', 'v': 'ව්',\n",
    "        'w': 'ව්', 's': 'ස්', 'h': 'හ්', 'f': 'ෆ්',\n",
    "        \n",
    "        # Common combinations and words\n",
    "        'me': 'මේ', 'mee': 'මී', 'mama': 'මම', 'maama': 'මාමා',\n",
    "        'api': 'අපි', 'eka': 'එක', 'eke': 'එකේ',\n",
    "        'katha': 'කතා', 'kathaa': 'කතා', \n",
    "        'hoda': 'හොඳ', 'hodai': 'හොඳයි', 'honda': 'හොඳ',\n",
    "        'ane': 'අනේ', 'aam': 'ආම්', 'ama': 'අම',\n",
    "        'ne': 'නේ', 'nae': 'නෑ', 'neh': 'නෙහ්',\n",
    "        'muta': 'මුට', 'mutaa': 'මුටා', 'mata': 'මට',\n",
    "        'badi': 'බදි', 'baddi': 'බද්දි',\n",
    "        'gini': 'ගිනි', 'gini': 'ගිණි',\n",
    "        'digi': 'දිගි', 'dini': 'දිනි',\n",
    "        'mutaba': 'මුතබ', 'badigini': 'බදිගිනි',\n",
    "        \n",
    "        # Special characters and punctuation\n",
    "        '.': '।', ',': '،', '!': '!', '?': '?'\n",
    "    }\n",
    "    \n",
    "    # Clean the text\n",
    "    text = romanized_text.strip().lower()\n",
    "    \n",
    "    # Split into words and process each\n",
    "    words = text.split()\n",
    "    sinhala_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Remove punctuation for processing but remember it\n",
    "        punctuation = ''\n",
    "        clean_word = word\n",
    "        if word and word[-1] in '.!?,:;':\n",
    "            punctuation = word[-1]\n",
    "            clean_word = word[:-1]\n",
    "        \n",
    "        # Convert the word\n",
    "        converted_word = convert_word_improved(clean_word, conversion_map)\n",
    "        \n",
    "        # Add punctuation back\n",
    "        if punctuation:\n",
    "            if punctuation in conversion_map:\n",
    "                converted_word += conversion_map[punctuation]\n",
    "            else:\n",
    "                converted_word += punctuation\n",
    "        \n",
    "        sinhala_words.append(converted_word)\n",
    "    \n",
    "    return ' '.join(sinhala_words)\n",
    "\n",
    "def convert_word_improved(word, conversion_map):\n",
    "    \"\"\"Convert a single word using the conversion map with better logic\"\"\"\n",
    "    if not word:\n",
    "        return word\n",
    "    \n",
    "    # Try direct mapping first\n",
    "    if word in conversion_map:\n",
    "        return conversion_map[word]\n",
    "    \n",
    "    # Try to break down the word\n",
    "    result = \"\"\n",
    "    remaining = word\n",
    "    \n",
    "    # Sort conversion keys by length (longest first) for better matching\n",
    "    sorted_keys = sorted(conversion_map.keys(), key=len, reverse=True)\n",
    "    \n",
    "    while remaining:\n",
    "        found = False\n",
    "        for pattern in sorted_keys:\n",
    "            if remaining.startswith(pattern):\n",
    "                result += conversion_map[pattern]\n",
    "                remaining = remaining[len(pattern):]\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            # If no pattern matches, keep the character as is\n",
    "            result += remaining[0]\n",
    "            remaining = remaining[1:]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the improved conversion\n",
    "test_text = \"aam ne mutabadigini\"\n",
    "improved_result = improved_romanized_to_sinhala(test_text)\n",
    "\n",
    "print(f\"🔤 Improved Sinhala Conversion Test:\")\n",
    "print(f\"   📝 Input: '{test_text}'\")\n",
    "print(f\"   🇱🇰 Output: '{improved_result}'\")\n",
    "print(f\"✅ Improved conversion function ready!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
